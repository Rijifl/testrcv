{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e748607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: IMPORTS (UPDATED)\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel, WhiteKernel\n",
    "from sklearn.cross_decomposition import PLSRegression  # NEW\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# NEW: XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"✓ XGBoost available\")\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"⚠ XGBoost not installed. Run: pip install xgboost\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a950c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: CONFIGURATION - MODIFY THESE\n",
    "# =============================================================================\n",
    "\n",
    "FILE_PATH = \"your_data.xlsx\"           # <-- Your Excel file\n",
    "RESPONSE_COLUMN = \"yield\"              # <-- Your response variable name  \n",
    "EXCLUDE_COLUMNS = [\"experiment_id\"]    # <-- Columns to exclude from features\n",
    "TEST_SIZE = 0.2\n",
    "TOP_K = 5\n",
    "\n",
    "print(f\"Response: {RESPONSE_COLUMN}\")\n",
    "print(f\"Exclude: {EXCLUDE_COLUMNS}\")\n",
    "print(f\"Top K: {TOP_K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a92af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: LOAD DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Try loading your file, or create sample data for demo\n",
    "try:\n",
    "    df = pd.read_excel(FILE_PATH)\n",
    "    print(f\"✓ Loaded: {df.shape}\")\n",
    "except:\n",
    "    print(\"Creating sample chemical data...\")\n",
    "    np.random.seed(42)\n",
    "    n = 200\n",
    "    df = pd.DataFrame({\n",
    "        'experiment_id': range(1, n+1),\n",
    "        'temperature_C': np.random.uniform(20, 100, n),\n",
    "        'pressure_bar': np.random.uniform(1, 10, n),\n",
    "        'pH': np.random.uniform(2, 12, n),\n",
    "        'concentration_mol_L': np.random.exponential(0.5, n),\n",
    "        'reaction_time_min': np.random.uniform(5, 120, n),\n",
    "        'catalyst_amount_g': np.random.uniform(0.1, 5, n),\n",
    "        'stirring_speed_rpm': np.random.uniform(100, 1000, n),\n",
    "        'solvent_ratio': np.random.uniform(0.1, 0.9, n),\n",
    "        'humidity_percent': np.random.uniform(30, 80, n),\n",
    "        'particle_size_um': np.random.uniform(1, 100, n),\n",
    "    })\n",
    "    # Response with known relationships\n",
    "    df['yield'] = (\n",
    "        0.5 * df['temperature_C'] +\n",
    "        2.0 * df['catalyst_amount_g'] +\n",
    "        -0.3 * df['pH'] +\n",
    "        0.1 * df['reaction_time_min'] +\n",
    "        np.random.normal(0, 5, n)\n",
    "    ).clip(0, 100)\n",
    "    \n",
    "    # Add some missing values\n",
    "    df.loc[np.random.choice(n, 5), 'humidity_percent'] = np.nan\n",
    "    print(f\"✓ Sample data created: {df.shape}\")\n",
    "\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()[df.isnull().sum() > 0]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: PREPARE FEATURES AND TARGET\n",
    "# =============================================================================\n",
    "\n",
    "# Get numeric columns only, exclude specified columns and response\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_cols = [c for c in numeric_cols if c not in EXCLUDE_COLUMNS + [RESPONSE_COLUMN]]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[RESPONSE_COLUMN].copy()\n",
    "\n",
    "print(f\"Features ({len(feature_cols)}): {feature_cols}\")\n",
    "print(f\"Target: {RESPONSE_COLUMN}\")\n",
    "print(f\"Shape: X={X.shape}, y={y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: CHEMICAL DATA CHECKS\n",
    "# =============================================================================\n",
    "\n",
    "# Check for outliers (Z-score > 3)\n",
    "print(\"=\" * 50)\n",
    "print(\"OUTLIER DETECTION (Z-score > 3)\")\n",
    "print(\"=\" * 50)\n",
    "z_scores = np.abs((X - X.mean()) / X.std())\n",
    "outliers = (z_scores > 3).sum()\n",
    "for col in outliers[outliers > 0].index:\n",
    "    print(f\"  {col}: {outliers[col]} outliers\")\n",
    "if outliers.sum() == 0:\n",
    "    print(\"  No outliers detected\")\n",
    "\n",
    "# Check multicollinearity\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MULTICOLLINEARITY CHECK (|r| > 0.9)\")\n",
    "print(\"=\" * 50)\n",
    "corr = X.corr().abs()\n",
    "high_corr = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        if corr.iloc[i, j] > 0.9:\n",
    "            high_corr.append((corr.columns[i], corr.columns[j], corr.iloc[i, j]))\n",
    "            print(f\"  {corr.columns[i]} ↔ {corr.columns[j]}: {corr.iloc[i,j]:.3f}\")\n",
    "if not high_corr:\n",
    "    print(\"  No highly correlated features\")\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(X.corr(), annot=True, cmap='RdBu_r', center=0, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8276710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: TRAIN/TEST SPLIT (BEFORE STANDARDIZATION - NO LEAKAGE)\n",
    "# =============================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a95983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: IMPUTE MISSING VALUES (FIT ON TRAIN ONLY)\n",
    "# =============================================================================\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Fit on train, transform both\n",
    "X_train = pd.DataFrame(\n",
    "    imputer.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_test = pd.DataFrame(\n",
    "    imputer.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Handle missing in y\n",
    "train_mask = ~y_train.isnull()\n",
    "test_mask = ~y_test.isnull()\n",
    "X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
    "X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
    "\n",
    "print(f\"✓ Missing values imputed (fitted on training only)\")\n",
    "print(f\"  Final training: {len(X_train)}, test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: STANDARDIZATION (FIT ON TRAIN ONLY - NO LEAKAGE)\n",
    "# =============================================================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data ONLY\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Apply training statistics to test data\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(\"✓ Standardization complete (NO DATA LEAKAGE)\")\n",
    "print(\"  - Scaler fitted on training data only\")\n",
    "print(\"  - Training mean applied to test data\")\n",
    "print(f\"\\nTraining data stats (should be ~0 mean, ~1 std):\")\n",
    "print(X_train_scaled.describe().loc[['mean', 'std']].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90edc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: METHOD 1 - LINEAR REGRESSION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD 1: LINEAR REGRESSION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Coefficients as importance (absolute value for standardized data)\n",
    "lr_importance = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'coefficient': lr_model.coef_,\n",
    "    'importance': np.abs(lr_model.coef_)\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "lr_importance['rank'] = range(1, len(lr_importance) + 1)\n",
    "\n",
    "# Performance\n",
    "lr_train_r2 = r2_score(y_train, lr_model.predict(X_train_scaled))\n",
    "lr_test_r2 = r2_score(y_test, lr_model.predict(X_test_scaled))\n",
    "\n",
    "print(f\"\\nTrain R²: {lr_train_r2:.4f}\")\n",
    "print(f\"Test R²:  {lr_test_r2:.4f}\")\n",
    "print(f\"\\nFeature Importance (|coefficient|):\")\n",
    "print(lr_importance[['rank', 'feature', 'coefficient', 'importance']].to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if c > 0 else 'red' for c in lr_importance['coefficient']]\n",
    "plt.barh(lr_importance['feature'][::-1], lr_importance['importance'][::-1], color=colors[::-1])\n",
    "plt.xlabel('|Coefficient|')\n",
    "plt.title('Linear Regression Feature Importance\\n(Green=Positive, Red=Negative)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: METHOD 2 - RANDOM FOREST\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD 2: RANDOM FOREST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Built-in feature importance (MDI)\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'importance_mdi': rf_model.feature_importances_\n",
    "}).sort_values('importance_mdi', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Permutation importance (more reliable)\n",
    "print(\"\\nCalculating permutation importance...\")\n",
    "perm_result = permutation_importance(\n",
    "    rf_model, X_test_scaled, y_test,\n",
    "    n_repeats=30, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "rf_importance['importance_perm'] = [\n",
    "    perm_result.importances_mean[list(X_train_scaled.columns).index(f)] \n",
    "    for f in rf_importance['feature']\n",
    "]\n",
    "rf_importance['rank'] = range(1, len(rf_importance) + 1)\n",
    "\n",
    "# Performance\n",
    "rf_train_r2 = r2_score(y_train, rf_model.predict(X_train_scaled))\n",
    "rf_test_r2 = r2_score(y_test, rf_model.predict(X_test_scaled))\n",
    "\n",
    "print(f\"\\nTrain R²: {rf_train_r2:.4f}\")\n",
    "print(f\"Test R²:  {rf_test_r2:.4f}\")\n",
    "print(f\"\\nFeature Importance:\")\n",
    "print(rf_importance[['rank', 'feature', 'importance_mdi', 'importance_perm']].to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "axes[0].barh(rf_importance['feature'][::-1], rf_importance['importance_mdi'][::-1], color='forestgreen')\n",
    "axes[0].set_xlabel('Importance (MDI)')\n",
    "axes[0].set_title('Random Forest - Mean Decrease Impurity')\n",
    "\n",
    "rf_perm_sorted = rf_importance.sort_values('importance_perm', ascending=False)\n",
    "axes[1].barh(rf_perm_sorted['feature'][::-1], rf_perm_sorted['importance_perm'][::-1], color='steelblue')\n",
    "axes[1].set_xlabel('Importance (Permutation)')\n",
    "axes[1].set_title('Random Forest - Permutation Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: METHOD 3 - GAUSSIAN PROCESS (BAYESIAN)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD 3: GAUSSIAN PROCESS (BAYESIAN)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Subsample if needed (GP is O(n³))\n",
    "max_samples = 500\n",
    "if len(X_train_scaled) > max_samples:\n",
    "    print(f\"Subsampling to {max_samples} for GP (computational efficiency)\")\n",
    "    idx = np.random.choice(len(X_train_scaled), max_samples, replace=False)\n",
    "    X_train_gp = X_train_scaled.iloc[idx]\n",
    "    y_train_gp = y_train.iloc[idx]\n",
    "else:\n",
    "    X_train_gp = X_train_scaled\n",
    "    y_train_gp = y_train\n",
    "\n",
    "# Kernel with ARD\n",
    "n_features = X_train_scaled.shape[1]\n",
    "kernel = ConstantKernel(1.0) * Matern(length_scale=np.ones(n_features), nu=2.5) + WhiteKernel(1.0)\n",
    "\n",
    "print(\"Fitting Gaussian Process (may take a moment)...\")\n",
    "gp_model = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    normalize_y=True\n",
    ")\n",
    "gp_model.fit(X_train_gp, y_train_gp)\n",
    "\n",
    "# Permutation importance\n",
    "print(\"Calculating permutation importance...\")\n",
    "gp_perm = permutation_importance(\n",
    "    gp_model, X_test_scaled, y_test,\n",
    "    n_repeats=10, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "\n",
    "gp_importance = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'importance': gp_perm.importances_mean,\n",
    "    'importance_std': gp_perm.importances_std\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "gp_importance['rank'] = range(1, len(gp_importance) + 1)\n",
    "\n",
    "# Performance\n",
    "gp_train_r2 = r2_score(y_train_gp, gp_model.predict(X_train_gp))\n",
    "gp_test_r2 = r2_score(y_test, gp_model.predict(X_test_scaled))\n",
    "\n",
    "print(f\"\\nTrain R²: {gp_train_r2:.4f}\")\n",
    "print(f\"Test R²:  {gp_test_r2:.4f}\")\n",
    "print(f\"\\nFeature Importance (Permutation):\")\n",
    "print(gp_importance[['rank', 'feature', 'importance', 'importance_std']].to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(gp_importance['feature'][::-1], gp_importance['importance'][::-1], \n",
    "         xerr=gp_importance['importance_std'][::-1], color='darkorange', capsize=3)\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.title('Gaussian Process - Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 12: METHOD 4 - XGBOOST\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "WHY XGBOOST FOR CHEMISTRY:\n",
    "- State-of-the-art predictive performance\n",
    "- Handles non-linear relationships\n",
    "- Built-in regularization prevents overfitting\n",
    "- Handles missing values natively\n",
    "- Fast training\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"METHOD 4: XGBOOST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not XGBOOST_AVAILABLE:\n",
    "    print(\"⚠ XGBoost not installed. Skipping...\")\n",
    "    xgb_importance = None\n",
    "    xgb_test_r2 = 0\n",
    "else:\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbosity=0\n",
    "    )\n",
    "    xgb_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Built-in feature importance (gain-based)\n",
    "    xgb_importance = pd.DataFrame({\n",
    "        'feature': X_train_scaled.columns,\n",
    "        'importance_gain': xgb_model.feature_importances_\n",
    "    }).sort_values('importance_gain', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Permutation importance\n",
    "    print(\"Calculating permutation importance...\")\n",
    "    xgb_perm = permutation_importance(\n",
    "        xgb_model, X_test_scaled, y_test,\n",
    "        n_repeats=30, random_state=RANDOM_STATE, n_jobs=-1\n",
    "    )\n",
    "    xgb_importance['importance_perm'] = [\n",
    "        xgb_perm.importances_mean[list(X_train_scaled.columns).index(f)]\n",
    "        for f in xgb_importance['feature']\n",
    "    ]\n",
    "    xgb_importance['rank'] = range(1, len(xgb_importance) + 1)\n",
    "    \n",
    "    # Performance\n",
    "    xgb_train_r2 = r2_score(y_train, xgb_model.predict(X_train_scaled))\n",
    "    xgb_test_r2 = r2_score(y_test, xgb_model.predict(X_test_scaled))\n",
    "    xgb_train_rmse = np.sqrt(mean_squared_error(y_train, xgb_model.predict(X_train_scaled)))\n",
    "    xgb_test_rmse = np.sqrt(mean_squared_error(y_test, xgb_model.predict(X_test_scaled)))\n",
    "    \n",
    "    print(f\"\\nTrain R²: {xgb_train_r2:.4f}, RMSE: {xgb_train_rmse:.4f}\")\n",
    "    print(f\"Test R²:  {xgb_test_r2:.4f}, RMSE: {xgb_test_rmse:.4f}\")\n",
    "    print(f\"\\nFeature Importance:\")\n",
    "    print(xgb_importance[['rank', 'feature', 'importance_gain', 'importance_perm']].to_string(index=False))\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    axes[0].barh(xgb_importance['feature'][::-1], xgb_importance['importance_gain'][::-1], color='darkgreen')\n",
    "    axes[0].set_xlabel('Importance (Gain)')\n",
    "    axes[0].set_title('XGBoost - Gain-based Importance')\n",
    "    \n",
    "    xgb_perm_sorted = xgb_importance.sort_values('importance_perm', ascending=False)\n",
    "    axes[1].barh(xgb_perm_sorted['feature'][::-1], xgb_perm_sorted['importance_perm'][::-1], color='teal')\n",
    "    axes[1].set_xlabel('Importance (Permutation)')\n",
    "    axes[1].set_title('XGBoost - Permutation Importance')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89162d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 13: METHOD 5 - PLS REGRESSION\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "WHY PLS FOR CHEMISTRY:\n",
    "- Standard method in chemometrics\n",
    "- Handles multicollinearity (common in chemical data)\n",
    "- Works when features > samples\n",
    "- VIP scores are the standard importance metric in chemistry\n",
    "- Finds latent variables explaining both X and y\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"METHOD 5: PLS REGRESSION (Partial Least Squares)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find optimal number of components via cross-validation\n",
    "max_components = min(10, X_train_scaled.shape[1], len(X_train_scaled) - 1)\n",
    "cv_scores = []\n",
    "\n",
    "print(\"Finding optimal number of components...\")\n",
    "for n_comp in range(1, max_components + 1):\n",
    "    pls_temp = PLSRegression(n_components=n_comp)\n",
    "    scores = cross_val_score(pls_temp, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "optimal_components = np.argmax(cv_scores) + 1\n",
    "print(f\"Optimal components: {optimal_components} (CV R² = {max(cv_scores):.4f})\")\n",
    "\n",
    "# Fit final model\n",
    "pls_model = PLSRegression(n_components=optimal_components)\n",
    "pls_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# Calculate VIP scores (Variable Importance in Projection)\n",
    "def calculate_vip_scores(model, X):\n",
    "    \"\"\"\n",
    "    Calculate VIP (Variable Importance in Projection) scores.\n",
    "    VIP > 1 is typically considered important in chemometrics.\n",
    "    \"\"\"\n",
    "    t = model.x_scores_  # X scores\n",
    "    w = model.x_weights_  # X weights\n",
    "    q = model.y_loadings_  # Y loadings\n",
    "    \n",
    "    n_features, n_components = w.shape\n",
    "    \n",
    "    # Calculate sum of squares of Y explained by each component\n",
    "    ss_y = np.sum(t ** 2, axis=0) * q.flatten() ** 2\n",
    "    ss_y_total = np.sum(ss_y)\n",
    "    \n",
    "    # Calculate VIP for each feature\n",
    "    vip_scores = np.zeros(n_features)\n",
    "    for i in range(n_features):\n",
    "        weight_sum = 0\n",
    "        for j in range(n_components):\n",
    "            weight_sum += (w[i, j] ** 2) * ss_y[j] / (np.sum(w[:, j] ** 2))\n",
    "        vip_scores[i] = np.sqrt(n_features * weight_sum / ss_y_total)\n",
    "    \n",
    "    return vip_scores\n",
    "\n",
    "\n",
    "vip_scores = calculate_vip_scores(pls_model, X_train_scaled)\n",
    "\n",
    "# Create importance dataframe\n",
    "pls_importance = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'VIP': vip_scores,\n",
    "    'coefficient': pls_model.coef_.flatten(),\n",
    "    'abs_coefficient': np.abs(pls_model.coef_.flatten())\n",
    "}).sort_values('VIP', ascending=False).reset_index(drop=True)\n",
    "pls_importance['rank'] = range(1, len(pls_importance) + 1)\n",
    "\n",
    "# Performance\n",
    "pls_train_r2 = r2_score(y_train, pls_model.predict(X_train_scaled))\n",
    "pls_test_r2 = r2_score(y_test, pls_model.predict(X_test_scaled))\n",
    "pls_train_rmse = np.sqrt(mean_squared_error(y_train, pls_model.predict(X_train_scaled)))\n",
    "pls_test_rmse = np.sqrt(mean_squared_error(y_test, pls_model.predict(X_test_scaled)))\n",
    "\n",
    "print(f\"\\nTrain R²: {pls_train_r2:.4f}, RMSE: {pls_train_rmse:.4f}\")\n",
    "print(f\"Test R²:  {pls_test_r2:.4f}, RMSE: {pls_test_rmse:.4f}\")\n",
    "\n",
    "print(f\"\\nFeature Importance (VIP > 1 = important in chemometrics):\")\n",
    "print(pls_importance[['rank', 'feature', 'VIP', 'coefficient']].to_string(index=False))\n",
    "\n",
    "# Identify important features by VIP threshold\n",
    "important_vip = pls_importance[pls_importance['VIP'] >= 1.0]['feature'].tolist()\n",
    "moderately_important = pls_importance[(pls_importance['VIP'] >= 0.8) & (pls_importance['VIP'] < 1.0)]['feature'].tolist()\n",
    "less_important = pls_importance[pls_importance['VIP'] < 0.8]['feature'].tolist()\n",
    "\n",
    "print(f\"\\n✓ Important (VIP ≥ 1.0): {important_vip}\")\n",
    "print(f\"⚠ Moderate (0.8 ≤ VIP < 1.0): {moderately_important}\")\n",
    "print(f\"✗ Less Important (VIP < 0.8): {less_important}\")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# VIP scores plot\n",
    "colors = ['darkgreen' if v >= 1.0 else 'orange' if v >= 0.8 else 'lightcoral' \n",
    "          for v in pls_importance['VIP']]\n",
    "axes[0].barh(pls_importance['feature'][::-1], pls_importance['VIP'][::-1], color=colors[::-1])\n",
    "axes[0].axvline(x=1.0, color='red', linestyle='--', linewidth=2, label='VIP = 1.0 threshold')\n",
    "axes[0].axvline(x=0.8, color='orange', linestyle='--', linewidth=1, label='VIP = 0.8')\n",
    "axes[0].set_xlabel('VIP Score')\n",
    "axes[0].set_title('PLS - Variable Importance in Projection (VIP)\\n(Green ≥1.0, Orange ≥0.8, Red <0.8)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Coefficient plot\n",
    "coef_colors = ['forestgreen' if c > 0 else 'crimson' for c in pls_importance['coefficient']]\n",
    "axes[1].barh(pls_importance['feature'][::-1], pls_importance['abs_coefficient'][::-1], color=coef_colors[::-1])\n",
    "axes[1].set_xlabel('|Coefficient|')\n",
    "axes[1].set_title('PLS - Regression Coefficients\\n(Green = Positive, Red = Negative)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Component scores plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(range(1, max_components + 1), cv_scores, 'bo-', linewidth=2, markersize=8)\n",
    "ax.axvline(x=optimal_components, color='red', linestyle='--', label=f'Optimal = {optimal_components}')\n",
    "ax.set_xlabel('Number of Components')\n",
    "ax.set_ylabel('Cross-Validation R²')\n",
    "ax.set_title('PLS Component Selection')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 14: AGGREGATE RANKINGS (UPDATED FOR 5 METHODS)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AGGREGATED RANKINGS (ALL 5 METHODS)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create ranking from each method\n",
    "features = list(X_train_scaled.columns)\n",
    "\n",
    "# Linear Regression ranking\n",
    "lr_ranking = lr_importance[['feature']].copy()\n",
    "lr_ranking['rank_lr'] = range(1, len(lr_ranking) + 1)\n",
    "\n",
    "# Random Forest ranking\n",
    "rf_ranking = rf_importance[['feature']].copy()\n",
    "rf_ranking['rank_rf'] = range(1, len(rf_ranking) + 1)\n",
    "\n",
    "# Gaussian Process ranking\n",
    "gp_ranking = gp_importance[['feature']].copy()\n",
    "gp_ranking['rank_gp'] = range(1, len(gp_ranking) + 1)\n",
    "\n",
    "# XGBoost ranking\n",
    "if xgb_importance is not None:\n",
    "    xgb_ranking = xgb_importance[['feature']].copy()\n",
    "    xgb_ranking['rank_xgb'] = range(1, len(xgb_ranking) + 1)\n",
    "else:\n",
    "    xgb_ranking = pd.DataFrame({'feature': features, 'rank_xgb': [np.nan] * len(features)})\n",
    "\n",
    "# PLS ranking (by VIP score)\n",
    "pls_ranking = pls_importance[['feature']].copy()\n",
    "pls_ranking['rank_pls'] = range(1, len(pls_ranking) + 1)\n",
    "\n",
    "# Merge all rankings\n",
    "combined = lr_ranking.merge(rf_ranking, on='feature')\n",
    "combined = combined.merge(gp_ranking, on='feature')\n",
    "combined = combined.merge(xgb_ranking, on='feature')\n",
    "combined = combined.merge(pls_ranking, on='feature')\n",
    "\n",
    "# Calculate average rank (handling potential NaN from XGBoost)\n",
    "rank_cols = ['rank_lr', 'rank_rf', 'rank_gp', 'rank_xgb', 'rank_pls']\n",
    "combined['avg_rank'] = combined[rank_cols].mean(axis=1, skipna=True)\n",
    "combined = combined.sort_values('avg_rank').reset_index(drop=True)\n",
    "combined['final_rank'] = range(1, len(combined) + 1)\n",
    "\n",
    "# Add agreement score (how many methods agree on top 5)\n",
    "def count_top_k_agreement(row, k=5):\n",
    "    count = 0\n",
    "    for col in rank_cols:\n",
    "        if pd.notna(row[col]) and row[col] <= k:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "combined['top5_agreement'] = combined.apply(lambda row: count_top_k_agreement(row, k=5), axis=1)\n",
    "\n",
    "print(\"\\nConsensus Ranking (All 5 Methods):\")\n",
    "print(combined[['final_rank', 'feature', 'rank_lr', 'rank_rf', 'rank_gp', 'rank_xgb', 'rank_pls', 'avg_rank', 'top5_agreement']].to_string(index=False))\n",
    "\n",
    "# Get top K\n",
    "top_k_features = combined.head(TOP_K)['feature'].tolist()\n",
    "print(f\"\\n✓ TOP {TOP_K} FEATURES (by consensus): {top_k_features}\")\n",
    "\n",
    "# Show high-agreement features\n",
    "high_agreement = combined[combined['top5_agreement'] >= 3]['feature'].tolist()\n",
    "print(f\"\\n✓ HIGH AGREEMENT FEATURES (≥3 methods rank in top 5): {high_agreement}\")\n",
    "\n",
    "# Store for later use\n",
    "consensus_ranking = combined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 15: RANKING VISUALIZATION (UPDATED FOR 5 METHODS)\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Bar comparison for top features\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(len(consensus_ranking.head(TOP_K)))\n",
    "width = 0.15\n",
    "\n",
    "ax1.bar(x - 2*width, consensus_ranking.head(TOP_K)['rank_lr'], width, label='Linear Reg', color='steelblue')\n",
    "ax1.bar(x - width, consensus_ranking.head(TOP_K)['rank_rf'], width, label='Random Forest', color='forestgreen')\n",
    "ax1.bar(x, consensus_ranking.head(TOP_K)['rank_gp'], width, label='Gaussian Process', color='darkorange')\n",
    "if xgb_importance is not None:\n",
    "    ax1.bar(x + width, consensus_ranking.head(TOP_K)['rank_xgb'], width, label='XGBoost', color='teal')\n",
    "ax1.bar(x + 2*width, consensus_ranking.head(TOP_K)['rank_pls'], width, label='PLS', color='purple')\n",
    "\n",
    "ax1.set_xlabel('Feature')\n",
    "ax1.set_ylabel('Rank (lower = better)')\n",
    "ax1.set_title(f'Ranking Comparison - Top {TOP_K} Features')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(consensus_ranking.head(TOP_K)['feature'], rotation=45, ha='right')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# 2. Heatmap of all rankings\n",
    "ax2 = axes[0, 1]\n",
    "heatmap_cols = ['rank_lr', 'rank_rf', 'rank_gp', 'rank_xgb', 'rank_pls']\n",
    "heatmap_data = consensus_ranking.set_index('feature')[heatmap_cols].head(10)\n",
    "heatmap_data.columns = ['Linear Reg', 'Random Forest', 'Gaussian Proc', 'XGBoost', 'PLS']\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap='RdYlGn_r', ax=ax2, cbar_kws={'label': 'Rank'})\n",
    "ax2.set_title('Feature Rankings Heatmap (Top 10)\\n(Lower = More Important)')\n",
    "\n",
    "# 3. Agreement visualization\n",
    "ax3 = axes[1, 0]\n",
    "agreement_data = consensus_ranking.head(10)\n",
    "colors = ['darkgreen' if a >= 4 else 'orange' if a >= 3 else 'lightcoral' for a in agreement_data['top5_agreement']]\n",
    "ax3.barh(agreement_data['feature'][::-1], agreement_data['top5_agreement'][::-1], color=colors[::-1])\n",
    "ax3.axvline(x=3, color='orange', linestyle='--', linewidth=2, label='Good agreement (3+)')\n",
    "ax3.set_xlabel('Number of Methods Ranking in Top 5')\n",
    "ax3.set_title('Method Agreement on Top Features')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Model performance comparison\n",
    "ax4 = axes[1, 1]\n",
    "model_names = ['Linear Reg', 'Random Forest', 'Gaussian Proc', 'XGBoost', 'PLS']\n",
    "test_r2_scores = [lr_test_r2, rf_test_r2, gp_test_r2, \n",
    "                  xgb_test_r2 if xgb_importance is not None else 0, \n",
    "                  pls_test_r2]\n",
    "bar_colors = ['steelblue', 'forestgreen', 'darkorange', 'teal', 'purple']\n",
    "\n",
    "bars = ax4.bar(model_names, test_r2_scores, color=bar_colors)\n",
    "ax4.set_ylabel('Test R²')\n",
    "ax4.set_title('Model Performance Comparison')\n",
    "ax4.set_ylim(0, 1)\n",
    "\n",
    "for bar, score in zip(bars, test_r2_scores):\n",
    "    ax4.annotate(f'{score:.3f}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print model performance summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "performance_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Test_R2': test_r2_scores,\n",
    "    'Suitable_for_Feature_Importance': ['Yes' if r2 > 0.3 else 'Caution' if r2 > 0.15 else 'No' for r2 in test_r2_scores]\n",
    "})\n",
    "performance_df = performance_df.sort_values('Test_R2', ascending=False)\n",
    "print(performance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6130ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 16: MANUAL FEATURE SELECTION (UPDATED FOR 5 METHODS)\n",
    "# =============================================================================\n",
    "\n",
    "def select_features(features_to_use):\n",
    "    \"\"\"\n",
    "    Manually select which features to use.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    features_to_use : list\n",
    "        List of feature names to use\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    selected_features : list\n",
    "    \"\"\"\n",
    "    all_features = list(X_train_scaled.columns)\n",
    "    \n",
    "    invalid = [f for f in features_to_use if f not in all_features]\n",
    "    valid = [f for f in features_to_use if f in all_features]\n",
    "    \n",
    "    if invalid:\n",
    "        print(f\"⚠ Invalid features (ignored): {invalid}\")\n",
    "    \n",
    "    print(f\"\\n✓ Selected {len(valid)} features:\")\n",
    "    for i, f in enumerate(valid, 1):\n",
    "        lr_rank = int(lr_importance[lr_importance['feature'] == f]['rank'].values[0])\n",
    "        rf_rank = int(rf_importance[rf_importance['feature'] == f]['rank'].values[0])\n",
    "        gp_rank = int(gp_importance[gp_importance['feature'] == f]['rank'].values[0])\n",
    "        xgb_rank = int(xgb_importance[xgb_importance['feature'] == f]['rank'].values[0]) if xgb_importance is not None else 'N/A'\n",
    "        pls_rank = int(pls_importance[pls_importance['feature'] == f]['rank'].values[0])\n",
    "        vip = pls_importance[pls_importance['feature'] == f]['VIP'].values[0]\n",
    "        print(f\"  {i}. {f} (LR:{lr_rank}, RF:{rf_rank}, GP:{gp_rank}, XGB:{xgb_rank}, PLS:{pls_rank}, VIP:{vip:.2f})\")\n",
    "    \n",
    "    return valid\n",
    "\n",
    "\n",
    "def show_all_features():\n",
    "    \"\"\"Display all available features with their rankings from all 5 methods.\"\"\"\n",
    "    print(\"\\nALL AVAILABLE FEATURES (Ranked by 5 Methods):\")\n",
    "    print(\"-\" * 90)\n",
    "    print(f\"{'#':<4} {'Feature':<22} {'LR':<5} {'RF':<5} {'GP':<5} {'XGB':<5} {'PLS':<5} {'VIP':<6} {'Avg':<6}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for _, row in consensus_ranking.iterrows():\n",
    "        vip = pls_importance[pls_importance['feature'] == row['feature']]['VIP'].values[0]\n",
    "        xgb_rank = f\"{int(row['rank_xgb'])}\" if pd.notna(row['rank_xgb']) else 'N/A'\n",
    "        print(f\"{int(row['final_rank']):<4} {row['feature']:<22} \"\n",
    "              f\"{int(row['rank_lr']):<5} {int(row['rank_rf']):<5} \"\n",
    "              f\"{int(row['rank_gp']):<5} {xgb_rank:<5} {int(row['rank_pls']):<5} \"\n",
    "              f\"{vip:<6.2f} {row['avg_rank']:<6.2f}\")\n",
    "\n",
    "\n",
    "def use_top_k(k):\n",
    "    \"\"\"Select top K features from consensus ranking.\"\"\"\n",
    "    features = consensus_ranking.head(k)['feature'].tolist()\n",
    "    print(f\"✓ Selected top {k} features: {features}\")\n",
    "    return features\n",
    "\n",
    "\n",
    "def use_high_agreement(min_agreement=3):\n",
    "    \"\"\"Select features where at least min_agreement methods rank them in top 5.\"\"\"\n",
    "    features = consensus_ranking[consensus_ranking['top5_agreement'] >= min_agreement]['feature'].tolist()\n",
    "    print(f\"✓ Selected {len(features)} features with ≥{min_agreement} methods agreement: {features}\")\n",
    "    return features\n",
    "\n",
    "\n",
    "def use_vip_threshold(threshold=1.0):\n",
    "    \"\"\"Select features with VIP score above threshold (chemometrics standard).\"\"\"\n",
    "    features = pls_importance[pls_importance['VIP'] >= threshold]['feature'].tolist()\n",
    "    print(f\"✓ Selected {len(features)} features with VIP ≥ {threshold}: {features}\")\n",
    "    return features\n",
    "\n",
    "\n",
    "# Show all options\n",
    "show_all_features()\n",
    "print(f\"\\nCurrent selection (top {TOP_K}): {top_k_features}\")\n",
    "print(f\"\\nSELECTION FUNCTIONS AVAILABLE:\")\n",
    "print(\"  - use_top_k(k)                    : Top K by average rank\")\n",
    "print(\"  - use_high_agreement(min=3)       : Features with method agreement\")\n",
    "print(\"  - use_vip_threshold(threshold=1.0): Features by PLS VIP score\")\n",
    "print(\"  - select_features(['feat1', ...]) : Manual selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 17: EXAMPLE - OVERRIDE FEATURE SELECTION (UPDATED)\n",
    "# =============================================================================\n",
    "\n",
    "# OPTION 1: Use top K from consensus (all 5 methods)\n",
    "selected_features = use_top_k(TOP_K)\n",
    "\n",
    "# OPTION 2: Use features with high method agreement\n",
    "# selected_features = use_high_agreement(min_agreement=3)\n",
    "\n",
    "# OPTION 3: Use chemometrics standard (VIP >= 1.0)\n",
    "# selected_features = use_vip_threshold(threshold=1.0)\n",
    "\n",
    "# OPTION 4: Manually select specific features\n",
    "# selected_features = select_features(['temperature_C', 'catalyst_amount_g', 'pH'])\n",
    "\n",
    "# OPTION 5: Combine approaches (intersection or union)\n",
    "# vip_features = set(use_vip_threshold(1.0))\n",
    "# consensus_features = set(use_top_k(5))\n",
    "# selected_features = list(vip_features & consensus_features)  # intersection\n",
    "# selected_features = list(vip_features | consensus_features)  # union\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL SELECTED FEATURES: {selected_features}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0770f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 18: FINAL MODEL WITH SELECTED FEATURES (UPDATED FOR 5 METHODS)\n",
    "# =============================================================================\n",
    "\n",
    "# Subset data to selected features\n",
    "X_train_final = X_train_scaled[selected_features]\n",
    "X_test_final = X_test_scaled[selected_features]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL MODEL COMPARISON (Selected Features Only)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Features used ({len(selected_features)}): {selected_features}\\n\")\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# 1. Linear Regression\n",
    "lr_final = LinearRegression()\n",
    "lr_final.fit(X_train_final, y_train)\n",
    "lr_r2_final = r2_score(y_test, lr_final.predict(X_test_final))\n",
    "lr_rmse_final = np.sqrt(mean_squared_error(y_test, lr_final.predict(X_test_final)))\n",
    "results_list.append(['Linear Regression', lr_r2_final, lr_rmse_final])\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_final = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_final.fit(X_train_final, y_train)\n",
    "rf_r2_final = r2_score(y_test, rf_final.predict(X_test_final))\n",
    "rf_rmse_final = np.sqrt(mean_squared_error(y_test, rf_final.predict(X_test_final)))\n",
    "results_list.append(['Random Forest', rf_r2_final, rf_rmse_final])\n",
    "\n",
    "# 3. Gaussian Process\n",
    "n_feat = len(selected_features)\n",
    "gp_kernel = ConstantKernel(1.0) * Matern(length_scale=np.ones(n_feat), nu=2.5) + WhiteKernel(1.0)\n",
    "gp_final = GaussianProcessRegressor(kernel=gp_kernel, n_restarts_optimizer=5, \n",
    "                                     random_state=RANDOM_STATE, normalize_y=True)\n",
    "gp_final.fit(X_train_final, y_train)\n",
    "gp_r2_final = r2_score(y_test, gp_final.predict(X_test_final))\n",
    "gp_rmse_final = np.sqrt(mean_squared_error(y_test, gp_final.predict(X_test_final)))\n",
    "results_list.append(['Gaussian Process', gp_r2_final, gp_rmse_final])\n",
    "\n",
    "# 4. XGBoost\n",
    "if XGBOOST_AVAILABLE:\n",
    "    xgb_final = xgb.XGBRegressor(n_estimators=100, max_depth=4, learning_rate=0.1,\n",
    "                                  random_state=RANDOM_STATE, verbosity=0)\n",
    "    xgb_final.fit(X_train_final, y_train)\n",
    "    xgb_r2_final = r2_score(y_test, xgb_final.predict(X_test_final))\n",
    "    xgb_rmse_final = np.sqrt(mean_squared_error(y_test, xgb_final.predict(X_test_final)))\n",
    "    results_list.append(['XGBoost', xgb_r2_final, xgb_rmse_final])\n",
    "\n",
    "# 5. PLS\n",
    "pls_final = PLSRegression(n_components=min(optimal_components, len(selected_features)))\n",
    "pls_final.fit(X_train_final, y_train)\n",
    "pls_r2_final = r2_score(y_test, pls_final.predict(X_test_final))\n",
    "pls_rmse_final = np.sqrt(mean_squared_error(y_test, pls_final.predict(X_test_final)))\n",
    "results_list.append(['PLS', pls_r2_final, pls_rmse_final])\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results_list, columns=['Model', 'Test_R2', 'Test_RMSE'])\n",
    "results_df = results_df.sort_values('Test_R2', ascending=False)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best_model = results_df.iloc[0]['Model']\n",
    "best_r2 = results_df.iloc[0]['Test_R2']\n",
    "print(f\"\\n✓ Best Model: {best_model} (R² = {best_r2:.4f})\")\n",
    "\n",
    "# Plot predictions for all models\n",
    "n_models = len(results_list)\n",
    "fig, axes = plt.subplots(1, n_models, figsize=(4*n_models, 4))\n",
    "\n",
    "models_dict = {\n",
    "    'Linear Regression': lr_final,\n",
    "    'Random Forest': rf_final,\n",
    "    'Gaussian Process': gp_final,\n",
    "    'PLS': pls_final\n",
    "}\n",
    "if XGBOOST_AVAILABLE:\n",
    "    models_dict['XGBoost'] = xgb_final\n",
    "\n",
    "for ax, (name, model) in zip(axes, models_dict.items()):\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    if len(y_pred.shape) > 1:\n",
    "        y_pred = y_pred.flatten()\n",
    "    \n",
    "    ax.scatter(y_test, y_pred, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    min_val = min(y_test.min(), y_pred.min())\n",
    "    max_val = max(y_test.max(), y_pred.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
    "    \n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    ax.set_title(f'{name}\\nR² = {r2:.4f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87956822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 19: EXPORT RESULTS (UPDATED)\n",
    "# =============================================================================\n",
    "\n",
    "# Save complete rankings to CSV\n",
    "consensus_ranking.to_csv('feature_rankings_5methods.csv', index=False)\n",
    "print(\"✓ Saved: feature_rankings_5methods.csv\")\n",
    "\n",
    "# Save individual method rankings\n",
    "lr_importance.to_csv('importance_linear_regression.csv', index=False)\n",
    "rf_importance.to_csv('importance_random_forest.csv', index=False)\n",
    "gp_importance.to_csv('importance_gaussian_process.csv', index=False)\n",
    "if xgb_importance is not None:\n",
    "    xgb_importance.to_csv('importance_xgboost.csv', index=False)\n",
    "pls_importance.to_csv('importance_pls.csv', index=False)\n",
    "print(\"✓ Saved: Individual importance files\")\n",
    "\n",
    "# Save selected features\n",
    "with open('selected_features.txt', 'w') as f:\n",
    "    f.write('\\n'.join(selected_features))\n",
    "print(\"✓ Saved: selected_features.txt\")\n",
    "\n",
    "# Save PLS VIP analysis\n",
    "vip_analysis = pls_importance[['feature', 'VIP', 'coefficient']].copy()\n",
    "vip_analysis['VIP_category'] = vip_analysis['VIP'].apply(\n",
    "    lambda x: 'Important (≥1.0)' if x >= 1.0 else 'Moderate (≥0.8)' if x >= 0.8 else 'Less Important (<0.8)'\n",
    ")\n",
    "vip_analysis.to_csv('pls_vip_analysis.csv', index=False)\n",
    "print(\"✓ Saved: pls_vip_analysis.csv\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total features analyzed: {len(feature_cols)}\")\n",
    "print(f\"Methods used: Linear Regression, Random Forest, Gaussian Process, XGBoost, PLS\")\n",
    "print(f\"Selected features ({len(selected_features)}): {selected_features}\")\n",
    "print(f\"Best model: {best_model} (R² = {best_r2:.4f})\")\n",
    "print(f\"\\nFeatures by PLS VIP:\")\n",
    "print(f\"  Important (VIP ≥ 1.0): {pls_importance[pls_importance['VIP'] >= 1.0]['feature'].tolist()}\")\n",
    "print(f\"  Moderate (VIP ≥ 0.8): {pls_importance[(pls_importance['VIP'] >= 0.8) & (pls_importance['VIP'] < 1.0)]['feature'].tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
