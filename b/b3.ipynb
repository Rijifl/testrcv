{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54bf026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENCAPSULATED FEATURE SCREENING MODULE\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class FeatureScreener:\n",
    "    \"\"\"Feature screening pipeline for Bayesian Optimization preparation.\"\"\"\n",
    "    \n",
    "    def __init__(self, response_column, target_features=4, maximize_response=False,\n",
    "                 correlation_strong=0.4, correlation_moderate=0.2,\n",
    "                 vip_important=1.0, vip_moderate=0.8,\n",
    "                 multicollinearity_threshold=0.7, interaction_threshold=0.3,\n",
    "                 random_state=42, test_size=0.2):\n",
    "        \n",
    "        self.response_column = response_column\n",
    "        self.target_features = target_features\n",
    "        self.maximize_response = maximize_response\n",
    "        self.correlation_strong = correlation_strong\n",
    "        self.correlation_moderate = correlation_moderate\n",
    "        self.vip_important = vip_important\n",
    "        self.vip_moderate = vip_moderate\n",
    "        self.multicollinearity_threshold = multicollinearity_threshold\n",
    "        self.interaction_threshold = interaction_threshold\n",
    "        self.random_state = random_state\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        self.binary_features = []\n",
    "        self.continuous_features = []\n",
    "        self.binary_mappings = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_cols = []\n",
    "        self.selected_features = []\n",
    "        self.consensus = None\n",
    "        self.bo_bounds_df = None\n",
    "        self.features_with_interactions = []\n",
    "        self.strong_interactions = pd.DataFrame()\n",
    "        \n",
    "    def classify_features(self, df, feature_list, verbose=True):\n",
    "        \"\"\"Classify features as binary or continuous and encode binary features.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"FEATURE TYPE CLASSIFICATION\")\n",
    "            print(\"=\" * 60)\n",
    "            print(\"Rule: Binary (2 unique) → 0/1 | Continuous (3+) → standardized\\n\")\n",
    "        \n",
    "        numeric_features = df[feature_list].select_dtypes(include=[np.number]).columns.tolist()\n",
    "        numeric_features = [c for c in numeric_features if c != self.response_column]\n",
    "        \n",
    "        for col in numeric_features:\n",
    "            n_unique = df[col].nunique()\n",
    "            if n_unique == 2:\n",
    "                self.binary_features.append(col)\n",
    "                unique_vals = df[col].dropna().unique()\n",
    "                mapping = {unique_vals[0]: 0, unique_vals[1]: 1}\n",
    "                df[col] = df[col].map(mapping)\n",
    "                self.binary_mappings[col] = mapping\n",
    "                if verbose:\n",
    "                    print(f\"  {col}: {n_unique} unique → BINARY ({unique_vals[0]}→0, {unique_vals[1]}→1)\")\n",
    "            else:\n",
    "                self.continuous_features.append(col)\n",
    "                if verbose:\n",
    "                    print(f\"  {col}: {n_unique} unique → CONTINUOUS\")\n",
    "        \n",
    "        self.feature_cols = self.binary_features + self.continuous_features\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n  Summary: {len(self.binary_features)} binary, {len(self.continuous_features)} continuous\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def prepare_data(self, df, verbose=True):\n",
    "        \"\"\"Prepare X and y, perform train-test split, then standardize.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"DATA PREPARATION\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        X = df[self.feature_cols].copy()\n",
    "        y = df[self.response_column].copy()\n",
    "        \n",
    "        valid = ~y.isnull()\n",
    "        n_dropped = (~valid).sum()\n",
    "        X, y = X[valid].reset_index(drop=True), y[valid].reset_index(drop=True)\n",
    "        \n",
    "        if verbose and n_dropped > 0:\n",
    "            print(f\"  Dropped {n_dropped} rows with missing response\")\n",
    "        \n",
    "        # Train-test split BEFORE standardization\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=self.test_size, random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Train/Test split: {len(X_train)}/{len(X_test)} samples ({1-self.test_size:.0%}/{self.test_size:.0%})\")\n",
    "        \n",
    "        # Store originals before scaling\n",
    "        self.original_X_train, self.original_y_train = X_train.copy(), y_train.copy()\n",
    "        self.original_X_test, self.original_y_test = X_test.copy(), y_test.copy()\n",
    "        \n",
    "        # Standardize continuous features using ONLY training data\n",
    "        X_train_scaled, X_test_scaled = X_train.copy(), X_test.copy()\n",
    "        if self.continuous_features:\n",
    "            X_train_scaled[self.continuous_features] = self.scaler.fit_transform(X_train[self.continuous_features])\n",
    "            X_test_scaled[self.continuous_features] = self.scaler.transform(X_test[self.continuous_features])\n",
    "            if verbose:\n",
    "                print(f\"  Standardized {len(self.continuous_features)} continuous features (fit on train only)\")\n",
    "        \n",
    "        # Scale binary to [-1, +1] for modeling\n",
    "        X_train_model, X_test_model = X_train_scaled.copy(), X_test_scaled.copy()\n",
    "        for col in self.binary_features:\n",
    "            X_train_model[col] = X_train_model[col] * 2 - 1\n",
    "            X_test_model[col] = X_test_model[col] * 2 - 1\n",
    "        \n",
    "        if verbose and self.binary_features:\n",
    "            print(f\"  Binary features scaled to [-1, +1] for modeling\")\n",
    "            print(f\"\\n  Samples/Features ratio: {len(X_train)/len(self.feature_cols):.1f}\")\n",
    "        \n",
    "        return X_train, X_test, X_train_model, X_test_model, y_train, y_test\n",
    "    \n",
    "    def compute_correlations(self, X, y, verbose=True):\n",
    "        \"\"\"Compute Pearson correlations.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"METHOD 1: PEARSON CORRELATION\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        correlations = X.corrwith(y)\n",
    "        corr_df = pd.DataFrame({\n",
    "            'feature': self.feature_cols,\n",
    "            'correlation': correlations.values,\n",
    "            'abs_corr': np.abs(correlations.values),\n",
    "            'type': ['binary' if f in self.binary_features else 'continuous' for f in self.feature_cols],\n",
    "            'direction': ['Positive' if c > 0 else 'Negative' for c in correlations.values]\n",
    "        }).sort_values('abs_corr', ascending=False).reset_index(drop=True)\n",
    "        corr_df['rank_corr'] = range(1, len(corr_df) + 1)\n",
    "        corr_df['strength'] = corr_df['correlation'].apply(\n",
    "            lambda r: 'Strong' if abs(r) >= self.correlation_strong else 'Moderate' if abs(r) >= self.correlation_moderate else 'Weak'\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nResults:\")\n",
    "            print(corr_df[['rank_corr', 'feature', 'correlation', 'direction', 'strength', 'type']].to_string(index=False))\n",
    "            \n",
    "            # Binary interpretation\n",
    "            binary_rows = corr_df[corr_df['type'] == 'binary']\n",
    "            if len(binary_rows) > 0:\n",
    "                print(\"\\nBinary Feature Effects:\")\n",
    "                for _, row in binary_rows.iterrows():\n",
    "                    effect = \"INCREASES\" if row['correlation'] > 0 else \"DECREASES\"\n",
    "                    print(f\"  {row['feature']}: When=1, response {effect} (r={row['correlation']:.3f})\")\n",
    "        \n",
    "        return corr_df\n",
    "    \n",
    "    def run_lasso(self, X_model, y, verbose=True):\n",
    "        \"\"\"Run Lasso regression for feature selection.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"METHOD 2: LASSO REGRESSION\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        lasso = LassoCV(cv=5, max_iter=10000, random_state=self.random_state)\n",
    "        lasso.fit(X_model, y)\n",
    "        \n",
    "        lasso_df = pd.DataFrame({\n",
    "            'feature': self.feature_cols,\n",
    "            'coefficient': lasso.coef_,\n",
    "            'abs_coef': np.abs(lasso.coef_),\n",
    "            'selected': lasso.coef_ != 0,\n",
    "            'type': ['binary' if f in self.binary_features else 'continuous' for f in self.feature_cols]\n",
    "        }).sort_values('abs_coef', ascending=False).reset_index(drop=True)\n",
    "        lasso_df['rank_lasso'] = range(1, len(lasso_df) + 1)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nOptimal alpha: {lasso.alpha_:.4f}\")\n",
    "            print(f\"Features selected: {lasso_df['selected'].sum()}/{len(lasso_df)}\")\n",
    "            print(\"\\nResults:\")\n",
    "            print(lasso_df[['rank_lasso', 'feature', 'coefficient', 'selected', 'type']].to_string(index=False))\n",
    "            selected = lasso_df[lasso_df['selected']]['feature'].tolist()\n",
    "            print(f\"\\n✓ Lasso selected: {selected if selected else 'None'}\")\n",
    "        \n",
    "        return lasso_df, lasso.alpha_\n",
    "    \n",
    "    def run_pls(self, X_model, y, verbose=True):\n",
    "        \"\"\"Run PLS and compute VIP scores.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"METHOD 3: PLS (VIP Scores)\")\n",
    "            print(\"=\" * 60)\n",
    "            print(\"\\nFinding optimal components...\")\n",
    "        \n",
    "        max_comp = min(5, len(self.feature_cols), len(X_model) - 1)\n",
    "        cv_scores = []\n",
    "        for n in range(1, max_comp + 1):\n",
    "            score = cross_val_score(PLSRegression(n_components=n), X_model, y, cv=5, scoring='r2').mean()\n",
    "            cv_scores.append(score)\n",
    "            if verbose:\n",
    "                print(f\"  {n} components: CV R² = {score:.4f}\")\n",
    "        \n",
    "        optimal_comp = np.argmax(cv_scores) + 1\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n✓ Optimal: {optimal_comp} components (CV R² = {max(cv_scores):.4f})\")\n",
    "        \n",
    "        pls = PLSRegression(n_components=optimal_comp)\n",
    "        pls.fit(X_model, y)\n",
    "        \n",
    "        # VIP calculation\n",
    "        t, w, q = pls.x_scores_, pls.x_weights_, pls.y_loadings_\n",
    "        m, p = w.shape\n",
    "        ss = np.sum(t**2, axis=0) * q.flatten()**2\n",
    "        total_ss = np.sum(ss)\n",
    "        vip = np.array([np.sqrt(m * sum((w[i,j]**2) * ss[j] / np.sum(w[:,j]**2) for j in range(p)) / total_ss) for i in range(m)])\n",
    "        \n",
    "        pls_df = pd.DataFrame({\n",
    "            'feature': self.feature_cols, 'VIP': vip,\n",
    "            'type': ['binary' if f in self.binary_features else 'continuous' for f in self.feature_cols]\n",
    "        }).sort_values('VIP', ascending=False).reset_index(drop=True)\n",
    "        pls_df['rank_pls'] = range(1, len(pls_df) + 1)\n",
    "        pls_df['category'] = pls_df['VIP'].apply(\n",
    "            lambda v: 'Important' if v >= self.vip_important else 'Moderate' if v >= self.vip_moderate else 'Less Important'\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nResults:\")\n",
    "            print(pls_df[['rank_pls', 'feature', 'VIP', 'category', 'type']].to_string(index=False))\n",
    "            important = pls_df[pls_df['category'] == 'Important']['feature'].tolist()\n",
    "            moderate = pls_df[pls_df['category'] == 'Moderate']['feature'].tolist()\n",
    "            print(f\"\\n✓ Important (VIP ≥ {self.vip_important}): {important if important else 'None'}\")\n",
    "            print(f\"⚠ Moderate (VIP ≥ {self.vip_moderate}): {moderate if moderate else 'None'}\")\n",
    "        \n",
    "        return pls_df, optimal_comp, cv_scores\n",
    "    \n",
    "    def screen_interactions(self, X, y, corr_df, verbose=True):\n",
    "        \"\"\"Screen for feature interactions.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"INTERACTION SCREENING\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Checking if effect of Feature A depends on level of Feature B.\")\n",
    "            print(f\"Threshold: {self.interaction_threshold}\\n\")\n",
    "        \n",
    "        top_features = corr_df.head(min(6, len(self.feature_cols)))['feature'].tolist()\n",
    "        results = []\n",
    "        \n",
    "        for f1, f2 in combinations(top_features, 2):\n",
    "            median_f2 = X[f2].median()\n",
    "            low_f2, high_f2 = X[f2] <= median_f2, X[f2] > median_f2\n",
    "            if low_f2.sum() >= 3 and high_f2.sum() >= 3:\n",
    "                corr_low = X.loc[low_f2, f1].corr(y[low_f2])\n",
    "                corr_high = X.loc[high_f2, f1].corr(y[high_f2])\n",
    "                if not np.isnan(corr_low) and not np.isnan(corr_high):\n",
    "                    strength = abs(corr_high - corr_low)\n",
    "                    results.append({\n",
    "                        'interaction': f'{f1} × {f2}', 'feature_1': f1, 'feature_2': f2,\n",
    "                        'corr_low_f2': corr_low, 'corr_high_f2': corr_high, 'strength': strength,\n",
    "                        'interpretation': 'Effect changes' if strength > self.interaction_threshold else 'No interaction'\n",
    "                    })\n",
    "        \n",
    "        if results:\n",
    "            interaction_df = pd.DataFrame(results).sort_values('strength', ascending=False)\n",
    "            strong = interaction_df[interaction_df['strength'] > self.interaction_threshold]\n",
    "            self.features_with_interactions = list(set(strong['feature_1'].tolist() + strong['feature_2'].tolist())) if len(strong) > 0 else []\n",
    "            self.strong_interactions = strong\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Interaction Analysis Results:\")\n",
    "                print(interaction_df[['interaction', 'corr_low_f2', 'corr_high_f2', 'strength', 'interpretation']].to_string(index=False))\n",
    "                \n",
    "                if len(strong) > 0:\n",
    "                    print(f\"\\n⚠️ POTENTIAL INTERACTIONS DETECTED:\")\n",
    "                    for _, row in strong.iterrows():\n",
    "                        print(f\"\\n  {row['interaction']}: strength = {row['strength']:.3f}\")\n",
    "                        print(f\"    When {row['feature_2']} LOW:  r = {row['corr_low_f2']:.3f}\")\n",
    "                        print(f\"    When {row['feature_2']} HIGH: r = {row['corr_high_f2']:.3f}\")\n",
    "                        print(f\"    → Include BOTH features in BO!\")\n",
    "                else:\n",
    "                    print(f\"\\n✓ No strong interactions detected (threshold: {self.interaction_threshold})\")\n",
    "        else:\n",
    "            interaction_df = pd.DataFrame()\n",
    "            self.strong_interactions = pd.DataFrame()\n",
    "            self.features_with_interactions = []\n",
    "            if verbose:\n",
    "                print(\"✓ No interactions to analyze (insufficient data or features)\")\n",
    "        \n",
    "        return interaction_df, self.strong_interactions, self.features_with_interactions\n",
    "    \n",
    "    def check_multicollinearity(self, X, verbose=True):\n",
    "        \"\"\"Check for multicollinearity between features.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"MULTICOLLINEARITY CHECK\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Checking correlations BETWEEN features.\")\n",
    "            print(f\"Threshold: |r| > {self.multicollinearity_threshold}\\n\")\n",
    "        \n",
    "        feature_corr = X.corr()\n",
    "        pairs = []\n",
    "        for i in range(len(self.feature_cols)):\n",
    "            for j in range(i+1, len(self.feature_cols)):\n",
    "                r = feature_corr.iloc[i, j]\n",
    "                if abs(r) > self.multicollinearity_threshold:\n",
    "                    pairs.append({'feature_1': self.feature_cols[i], 'feature_2': self.feature_cols[j], 'correlation': r})\n",
    "        \n",
    "        if verbose:\n",
    "            if pairs:\n",
    "                print(\"⚠️ HIGHLY CORRELATED PAIRS:\")\n",
    "                for pair in pairs:\n",
    "                    print(f\"  {pair['feature_1']} ↔ {pair['feature_2']}: r = {pair['correlation']:.3f}\")\n",
    "                    print(f\"    → Consider keeping only ONE in BO\")\n",
    "            else:\n",
    "                print(\"✓ No highly correlated feature pairs found\")\n",
    "        \n",
    "        return pairs, feature_corr\n",
    "    \n",
    "    def build_consensus(self, corr_df, lasso_df, pls_df, verbose=True):\n",
    "        \"\"\"Build consensus ranking from all methods.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"CONSENSUS RANKING (All Methods)\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        consensus = corr_df[['feature', 'rank_corr', 'correlation', 'direction', 'type', 'strength']].merge(\n",
    "            lasso_df[['feature', 'rank_lasso', 'selected']], on='feature'\n",
    "        ).merge(pls_df[['feature', 'rank_pls', 'VIP', 'category']], on='feature')\n",
    "        \n",
    "        consensus['avg_rank'] = consensus[['rank_corr', 'rank_lasso', 'rank_pls']].mean(axis=1)\n",
    "        consensus = consensus.sort_values('avg_rank').reset_index(drop=True)\n",
    "        consensus['final_rank'] = range(1, len(consensus) + 1)\n",
    "        consensus['methods_top3'] = consensus.apply(\n",
    "            lambda r: sum([r['rank_corr'] <= 3, r['rank_lasso'] <= 3, r['rank_pls'] <= 3]), axis=1\n",
    "        )\n",
    "        consensus['has_interaction'] = consensus['feature'].isin(self.features_with_interactions)\n",
    "        \n",
    "        # Score features\n",
    "        def score(row):\n",
    "            s = 0\n",
    "            if abs(row['correlation']) >= self.correlation_strong: s += 3\n",
    "            elif abs(row['correlation']) >= self.correlation_moderate: s += 2\n",
    "            if row['VIP'] >= self.vip_important: s += 3\n",
    "            elif row['VIP'] >= self.vip_moderate: s += 2\n",
    "            if row['selected']: s += 2\n",
    "            s += row['methods_top3']\n",
    "            if row['has_interaction']: s += 2\n",
    "            return s\n",
    "        \n",
    "        consensus['score'] = consensus.apply(score, axis=1)\n",
    "        self.consensus = consensus.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nConsensus Ranking:\")\n",
    "            display_cols = ['final_rank', 'feature', 'type', 'correlation', 'VIP', 'selected', \n",
    "                            'avg_rank', 'methods_top3', 'has_interaction']\n",
    "            print(self.consensus[display_cols].to_string(index=False))\n",
    "            \n",
    "            high_agreement = self.consensus[self.consensus['methods_top3'] >= 3]['feature'].tolist()\n",
    "            moderate_agreement = self.consensus[self.consensus['methods_top3'] == 2]['feature'].tolist()\n",
    "            print(f\"\\n✓ High agreement (3/3 methods in top 3): {high_agreement if high_agreement else 'None'}\")\n",
    "            print(f\"⚠ Moderate agreement (2/3 methods): {moderate_agreement if moderate_agreement else 'None'}\")\n",
    "        \n",
    "        return self.consensus\n",
    "    \n",
    "    def recommend_features(self, verbose=True):\n",
    "        \"\"\"Generate feature recommendations.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"FEATURE RECOMMENDATION\")\n",
    "            print(\"=\" * 60)\n",
    "            print(\"\\nFeature Scores:\")\n",
    "            print(self.consensus[['feature', 'type', 'correlation', 'VIP', 'selected', 'has_interaction', 'score']].to_string(index=False))\n",
    "        \n",
    "        recommended, reasons = [], {}\n",
    "        \n",
    "        for _, row in self.consensus.iterrows():\n",
    "            include, reason = False, []\n",
    "            if row['score'] >= 6: include, reason = True, [f\"High score ({row['score']})\"]\n",
    "            if abs(row['correlation']) >= self.correlation_strong: \n",
    "                include = True\n",
    "                if \"High score\" not in str(reason): reason.append(\"Strong correlation\")\n",
    "            if row['VIP'] >= self.vip_important: \n",
    "                include = True\n",
    "                if \"High score\" not in str(reason): reason.append(f\"VIP ≥ {self.vip_important}\")\n",
    "            if row['has_interaction'] and row['score'] >= 4: \n",
    "                include = True\n",
    "                reason.append(\"Part of interaction\")\n",
    "            \n",
    "            if include and len(recommended) < 6:\n",
    "                recommended.append(row['feature'])\n",
    "                reasons[row['feature']] = ', '.join(reason) if reason else \"High overall score\"\n",
    "        \n",
    "        # Ensure minimum\n",
    "        while len(recommended) < 3:\n",
    "            for _, row in self.consensus.iterrows():\n",
    "                if row['feature'] not in recommended:\n",
    "                    recommended.append(row['feature'])\n",
    "                    reasons[row['feature']] = \"Added to meet minimum\"\n",
    "                    break\n",
    "        \n",
    "        self.selected_features = recommended[:self.target_features]\n",
    "        self._recommendation_reasons = reasons\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"RECOMMENDED ({len(self.selected_features)} features):\")\n",
    "            print(f\"{'='*50}\")\n",
    "            for feat in self.selected_features:\n",
    "                row = self.consensus[self.consensus['feature'] == feat].iloc[0]\n",
    "                feat_type = \"[binary]\" if row['type'] == 'binary' else \"[continuous]\"\n",
    "                print(f\"\\n  ✓ {feat} {feat_type}\")\n",
    "                print(f\"      Correlation: {row['correlation']:.3f}\")\n",
    "                print(f\"      VIP: {row['VIP']:.2f}\")\n",
    "                print(f\"      Reason: {reasons.get(feat, 'N/A')}\")\n",
    "        \n",
    "        return self.selected_features, reasons\n",
    "    \n",
    "    def set_features_manual(self, feature_list, verbose=True):\n",
    "        \"\"\"\n",
    "        Manually override feature selection.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        feature_list : list - List of feature names to use\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"MANUAL FEATURE OVERRIDE\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        # Validate features exist\n",
    "        invalid = [f for f in feature_list if f not in self.feature_cols]\n",
    "        if invalid:\n",
    "            raise ValueError(f\"Invalid features: {invalid}. Available: {self.feature_cols}\")\n",
    "        \n",
    "        self.selected_features = feature_list\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n✓ Manually selected {len(feature_list)} features:\")\n",
    "            for i, feat in enumerate(feature_list, 1):\n",
    "                if self.consensus is not None:\n",
    "                    row = self.consensus[self.consensus['feature'] == feat].iloc[0]\n",
    "                    print(f\"  {i}. {feat} ({row['type']}) - corr: {row['correlation']:.3f}, VIP: {row['VIP']:.2f}\")\n",
    "                else:\n",
    "                    ftype = 'binary' if feat in self.binary_features else 'continuous'\n",
    "                    print(f\"  {i}. {feat} ({ftype})\")\n",
    "        \n",
    "        return self.selected_features\n",
    "    \n",
    "    def validate_selection(self, X_train, X_model, y, verbose=True):\n",
    "        \"\"\"Validate selected features for issues and run LOO-CV.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"FEATURE SELECTION VALIDATION\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"\\nSelected features ({len(self.selected_features)}):\")\n",
    "            for i, feat in enumerate(self.selected_features, 1):\n",
    "                row = self.consensus[self.consensus['feature'] == feat].iloc[0]\n",
    "                print(f\"  {i}. {feat} ({row['type']}) - corr: {row['correlation']:.3f}, VIP: {row['VIP']:.2f}\")\n",
    "        \n",
    "        issues = []\n",
    "        \n",
    "        # Check multicollinearity in selection\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"-\" * 40)\n",
    "            print(\"VALIDATION CHECKS:\")\n",
    "        \n",
    "        if len(self.selected_features) > 1:\n",
    "            sel_corr = X_train[self.selected_features].corr()\n",
    "            collinear_issues = []\n",
    "            for i in range(len(self.selected_features)):\n",
    "                for j in range(i+1, len(self.selected_features)):\n",
    "                    r = sel_corr.iloc[i, j]\n",
    "                    if abs(r) > self.multicollinearity_threshold:\n",
    "                        collinear_issues.append(f\"{self.selected_features[i]} ↔ {self.selected_features[j]}: r={r:.2f}\")\n",
    "            \n",
    "            if collinear_issues:\n",
    "                issues.extend(collinear_issues)\n",
    "                if verbose:\n",
    "                    print(f\"  ⚠️ Multicollinearity in selection:\")\n",
    "                    for issue in collinear_issues:\n",
    "                        print(f\"      {issue}\")\n",
    "            elif verbose:\n",
    "                print(f\"  ✓ No multicollinearity issues\")\n",
    "        \n",
    "        # Check broken interactions\n",
    "        if len(self.strong_interactions) > 0:\n",
    "            broken = []\n",
    "            for _, row in self.strong_interactions.iterrows():\n",
    "                f1, f2 = row['feature_1'], row['feature_2']\n",
    "                if (f1 in self.selected_features) != (f2 in self.selected_features):\n",
    "                    in1 = \"IN\" if f1 in self.selected_features else \"OUT\"\n",
    "                    in2 = \"IN\" if f2 in self.selected_features else \"OUT\"\n",
    "                    broken.append(f\"{f1} ({in1}) × {f2} ({in2})\")\n",
    "            \n",
    "            if broken:\n",
    "                issues.extend(broken)\n",
    "                if verbose:\n",
    "                    print(f\"  ⚠️ Broken interactions:\")\n",
    "                    for b in broken:\n",
    "                        print(f\"      {b}\")\n",
    "            elif verbose:\n",
    "                print(f\"  ✓ No broken interactions\")\n",
    "        elif verbose:\n",
    "            print(f\"  ✓ No interactions to check\")\n",
    "        \n",
    "        # LOO-CV\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"VALIDATION: Leave-One-Out Cross-Validation\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        X_sel = X_model[self.selected_features]\n",
    "        loo_preds, loo_actual = [], []\n",
    "        \n",
    "        for train_idx, test_idx in LeaveOneOut().split(X_sel):\n",
    "            model = RidgeCV(alphas=[0.1, 1, 10, 100], cv=3)\n",
    "            model.fit(X_sel.iloc[train_idx], y.iloc[train_idx])\n",
    "            loo_preds.append(model.predict(X_sel.iloc[test_idx])[0])\n",
    "            loo_actual.append(y.iloc[test_idx].values[0])\n",
    "        \n",
    "        loo_preds, loo_actual = np.array(loo_preds), np.array(loo_actual)\n",
    "        metrics = {\n",
    "            'r2': r2_score(loo_actual, loo_preds),\n",
    "            'rmse': np.sqrt(np.mean((loo_actual - loo_preds)**2)),\n",
    "            'mae': np.mean(np.abs(loo_actual - loo_preds))\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nLOO-CV Results ({len(self.selected_features)} features):\")\n",
    "            print(f\"  R²:   {metrics['r2']:.4f}\")\n",
    "            print(f\"  RMSE: {metrics['rmse']:.4f}\")\n",
    "            print(f\"  MAE:  {metrics['mae']:.4f}\")\n",
    "            \n",
    "            print(f\"\\nInterpretation:\")\n",
    "            if metrics['r2'] > 0.5:\n",
    "                print(\"  ✓ Good signal - features are predictive\")\n",
    "            elif metrics['r2'] > 0.2:\n",
    "                print(\"  ⚠️ Moderate signal - GP in BO can likely improve\")\n",
    "            elif metrics['r2'] > 0:\n",
    "                print(\"  ⚠️ Weak linear signal - may be non-linear\")\n",
    "            else:\n",
    "                print(\"  ⚠️ No linear signal - check data or feature selection\")\n",
    "        \n",
    "        return metrics, loo_preds, loo_actual, issues\n",
    "    \n",
    "    def generate_bo_bounds(self, original_X, verbose=True):\n",
    "        \"\"\"Generate Bayesian Optimization bounds.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"BAYESIAN OPTIMIZATION SEARCH SPACE\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        bounds = []\n",
    "        for feat in self.selected_features:\n",
    "            if feat in self.binary_features:\n",
    "                bounds.append({'feature': feat, 'type': 'binary', 'min': 0, 'max': 1, \n",
    "                               'observed_min': 0, 'observed_max': 1})\n",
    "            else:\n",
    "                fmin, fmax = original_X[feat].min(), original_X[feat].max()\n",
    "                margin = 0.1 * (fmax - fmin)\n",
    "                bounds.append({'feature': feat, 'type': 'continuous', 'min': fmin - margin, \n",
    "                               'max': fmax + margin, 'observed_min': fmin, 'observed_max': fmax})\n",
    "        \n",
    "        self.bo_bounds_df = pd.DataFrame(bounds)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nSearch Space Bounds:\")\n",
    "            print(self.bo_bounds_df.to_string(index=False))\n",
    "            \n",
    "            print(\"\\n\" + \"-\" * 40)\n",
    "            print(\"EFFECT DIRECTIONS:\")\n",
    "            for feat in self.selected_features:\n",
    "                row = self.consensus[self.consensus['feature'] == feat].iloc[0]\n",
    "                direction = row['correlation']\n",
    "                if self.maximize_response:\n",
    "                    suggest = \"HIGH\" if direction > 0 else \"LOW\"\n",
    "                else:\n",
    "                    suggest = \"LOW\" if direction > 0 else \"HIGH\"\n",
    "                print(f\"  {feat}: {'Positive' if direction > 0 else 'Negative'} effect → Suggest {suggest}\")\n",
    "        \n",
    "        return self.bo_bounds_df\n",
    "    \n",
    "    def export_for_bo(self, original_X, original_y, output_prefix='bo', verbose=True):\n",
    "        \"\"\"Export data for Bayesian Optimization.\"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"EXPORT FOR BAYESIAN OPTIMIZATION\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        bo_data = original_X[self.selected_features].copy()\n",
    "        bo_data[self.response_column] = original_y.values\n",
    "        \n",
    "        best_idx = original_y.idxmax() if self.maximize_response else original_y.idxmin()\n",
    "        best_val = original_y.max() if self.maximize_response else original_y.min()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nInitial Data:\")\n",
    "            print(f\"  Samples: {len(bo_data)}\")\n",
    "            print(f\"  Features: {len(self.selected_features)}\")\n",
    "            \n",
    "            print(f\"\\nBest Observed {'Maximum' if self.maximize_response else 'Minimum'}:\")\n",
    "            print(f\"  {self.response_column} = {best_val:.4f}\")\n",
    "            print(f\"  Conditions:\")\n",
    "            for feat in self.selected_features:\n",
    "                print(f\"    {feat}: {original_X.loc[best_idx, feat]:.4f}\")\n",
    "        \n",
    "        self.bo_bounds_df.to_csv(f'{output_prefix}_bounds.csv', index=False)\n",
    "        bo_data.to_csv(f'{output_prefix}_initial_data.csv', index=False)\n",
    "        \n",
    "        feature_info = self.consensus[self.consensus['feature'].isin(self.selected_features)][\n",
    "            ['feature', 'type', 'correlation', 'VIP', 'has_interaction']\n",
    "        ].reset_index(drop=True)\n",
    "        feature_info.to_csv(f'{output_prefix}_feature_info.csv', index=False)\n",
    "        \n",
    "        selected_binary = [f for f in self.selected_features if f in self.binary_features]\n",
    "        if selected_binary:\n",
    "            mappings = [{'feature': f, 'value_0': list(self.binary_mappings[f].keys())[0],\n",
    "                         'value_1': list(self.binary_mappings[f].keys())[1]} for f in selected_binary]\n",
    "            pd.DataFrame(mappings).to_csv(f'{output_prefix}_binary_mappings.csv', index=False)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n✓ Saved: {output_prefix}_bounds.csv\")\n",
    "            print(f\"✓ Saved: {output_prefix}_initial_data.csv\")\n",
    "            print(f\"✓ Saved: {output_prefix}_feature_info.csv\")\n",
    "            if selected_binary:\n",
    "                print(f\"✓ Saved: {output_prefix}_binary_mappings.csv\")\n",
    "        \n",
    "        return bo_data, best_idx, best_val\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PLOTTING METHODS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def plot_feature_vs_response(self, X, y):\n",
    "        \"\"\"Plot scatter/box plots of features vs response.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"VISUAL INSPECTION: Feature vs Response\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        n_feat = len(self.feature_cols)\n",
    "        n_cols = min(4, n_feat)\n",
    "        n_rows = int(np.ceil(n_feat / n_cols))\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 3.5*n_rows))\n",
    "        axes = axes.flatten() if n_feat > 1 else [axes]\n",
    "        \n",
    "        for i, col in enumerate(self.feature_cols):\n",
    "            ax = axes[i]\n",
    "            corr = X[col].corr(y)\n",
    "            \n",
    "            if col in self.binary_features:\n",
    "                for val in [0, 1]:\n",
    "                    data = y[X[col] == val]\n",
    "                    ax.boxplot([data], positions=[val], widths=0.6)\n",
    "                ax.set_xticks([0, 1])\n",
    "                ax.set_xticklabels(['0', '1'])\n",
    "                ax.set_xlabel(f'{col} (binary)')\n",
    "            else:\n",
    "                ax.scatter(X[col], y, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "                z = np.polyfit(X[col], y, 1)\n",
    "                p = np.poly1d(z)\n",
    "                x_line = np.linspace(X[col].min(), X[col].max(), 100)\n",
    "                ax.plot(x_line, p(x_line), 'r--', linewidth=2)\n",
    "                ax.set_xlabel(col)\n",
    "            \n",
    "            ax.set_ylabel(self.response_column)\n",
    "            ax.set_title(f'r = {corr:.3f}', fontsize=10)\n",
    "        \n",
    "        for j in range(i+1, len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.suptitle(f'Features vs {self.response_column}', fontsize=12, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"Look for: linear trends, non-linear patterns, outliers\")\n",
    "    \n",
    "    def plot_response_distribution(self, y):\n",
    "        \"\"\"Plot response variable distribution.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"RESPONSE DISTRIBUTION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        ax1 = axes[0]\n",
    "        ax1.hist(y, bins=15, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "        ax1.axvline(y.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {y.mean():.2f}')\n",
    "        ax1.axvline(y.median(), color='orange', linestyle='--', linewidth=2, label=f'Median: {y.median():.2f}')\n",
    "        ax1.set_xlabel(self.response_column)\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('Response Distribution')\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2 = axes[1]\n",
    "        ax2.boxplot(y, vert=True)\n",
    "        ax2.set_ylabel(self.response_column)\n",
    "        ax2.set_title('Response Box Plot')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Response statistics:\")\n",
    "        print(f\"  Min:    {y.min():.4f}\")\n",
    "        print(f\"  Max:    {y.max():.4f}\")\n",
    "        print(f\"  Mean:   {y.mean():.4f}\")\n",
    "        print(f\"  Median: {y.median():.4f}\")\n",
    "        print(f\"  Std:    {y.std():.4f}\")\n",
    "    \n",
    "    def plot_correlation(self, corr_df):\n",
    "        \"\"\"Plot correlation analysis results.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        ax1 = axes[0]\n",
    "        colors = []\n",
    "        for _, row in corr_df.iterrows():\n",
    "            if row['correlation'] > 0:\n",
    "                colors.append('forestgreen' if row['type'] == 'continuous' else 'steelblue')\n",
    "            else:\n",
    "                colors.append('crimson' if row['type'] == 'continuous' else 'darkorange')\n",
    "        \n",
    "        ax1.barh(corr_df['feature'][::-1], corr_df['abs_corr'][::-1], color=colors[::-1])\n",
    "        ax1.axvline(x=self.correlation_strong, color='green', linestyle='--', linewidth=2, \n",
    "                    label=f'Strong ({self.correlation_strong})')\n",
    "        ax1.axvline(x=self.correlation_moderate, color='orange', linestyle='--', linewidth=1.5, \n",
    "                    label=f'Moderate ({self.correlation_moderate})')\n",
    "        ax1.set_xlabel('|Correlation|')\n",
    "        ax1.set_title('Feature-Response Correlation\\n(Green/Blue=Positive, Red/Orange=Negative)')\n",
    "        ax1.legend(loc='lower right')\n",
    "        \n",
    "        ax2 = axes[1]\n",
    "        colors_signed = ['forestgreen' if c > 0 else 'crimson' for c in corr_df['correlation']]\n",
    "        ax2.barh(corr_df['feature'][::-1], corr_df['correlation'][::-1], color=colors_signed[::-1])\n",
    "        ax2.axvline(x=0, color='black', linewidth=1)\n",
    "        ax2.set_xlabel('Correlation (with sign)')\n",
    "        ax2.set_title('Direction of Effect\\n(Green=Positive, Red=Negative)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_lasso(self, lasso_df):\n",
    "        \"\"\"Plot Lasso regression results.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        colors = ['forestgreen' if s else 'lightgray' for s in lasso_df['selected']]\n",
    "        plt.barh(lasso_df['feature'][::-1], lasso_df['abs_coef'][::-1], color=colors[::-1])\n",
    "        plt.xlabel('|Coefficient|')\n",
    "        plt.title('Lasso Coefficients\\n(Green = Selected, Gray = Eliminated)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_pls(self, pls_df, cv_scores):\n",
    "        \"\"\"Plot PLS VIP scores and component selection.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        ax1 = axes[0]\n",
    "        colors = ['darkgreen' if v >= self.vip_important else 'orange' if v >= self.vip_moderate else 'lightcoral' \n",
    "                  for v in pls_df['VIP']]\n",
    "        ax1.barh(pls_df['feature'][::-1], pls_df['VIP'][::-1], color=colors[::-1])\n",
    "        ax1.axvline(x=self.vip_important, color='green', linestyle='--', linewidth=2, \n",
    "                    label=f'Important ({self.vip_important})')\n",
    "        ax1.axvline(x=self.vip_moderate, color='orange', linestyle='--', linewidth=1.5, \n",
    "                    label=f'Moderate ({self.vip_moderate})')\n",
    "        ax1.set_xlabel('VIP Score')\n",
    "        ax1.set_title('PLS Variable Importance in Projection')\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2 = axes[1]\n",
    "        ax2.plot(range(1, len(cv_scores) + 1), cv_scores, 'bo-', linewidth=2, markersize=8)\n",
    "        optimal = np.argmax(cv_scores) + 1\n",
    "        ax2.axvline(x=optimal, color='red', linestyle='--', label=f'Optimal = {optimal}')\n",
    "        ax2.set_xlabel('Number of Components')\n",
    "        ax2.set_ylabel('CV R²')\n",
    "        ax2.set_title('PLS Component Selection')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_interactions(self, interaction_df):\n",
    "        \"\"\"Plot interaction screening results.\"\"\"\n",
    "        if len(interaction_df) == 0:\n",
    "            print(\"No interactions to plot\")\n",
    "            return\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        colors = ['crimson' if s > self.interaction_threshold else 'steelblue' for s in interaction_df['strength']]\n",
    "        ax.barh(interaction_df['interaction'][::-1], interaction_df['strength'][::-1], color=colors[::-1])\n",
    "        ax.axvline(x=self.interaction_threshold, color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'Threshold ({self.interaction_threshold})')\n",
    "        ax.set_xlabel('Interaction Strength')\n",
    "        ax.set_title('Interaction Screening\\n(Red = Potential Interaction)')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_multicollinearity(self, feature_corr):\n",
    "        \"\"\"Plot feature correlation heatmap.\"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        mask = np.triu(np.ones_like(feature_corr, dtype=bool), k=0)\n",
    "        sns.heatmap(feature_corr, annot=True, cmap='RdBu_r', center=0, fmt='.2f',\n",
    "                    mask=mask, square=True, linewidths=0.5)\n",
    "        plt.title('Feature-Feature Correlations\\n(Check for multicollinearity)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_consensus(self):\n",
    "        \"\"\"Plot consensus ranking visualization.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"CONSENSUS VISUALIZATION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # 1. Heatmap of rankings\n",
    "        ax1 = axes[0, 0]\n",
    "        heatmap_data = self.consensus.set_index('feature')[['rank_corr', 'rank_lasso', 'rank_pls']]\n",
    "        heatmap_data.columns = ['Correlation', 'Lasso', 'PLS']\n",
    "        sns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap='RdYlGn_r', ax=ax1,\n",
    "                    cbar_kws={'label': 'Rank (lower=better)'})\n",
    "        ax1.set_title('Rankings Across Methods')\n",
    "        \n",
    "        # 2. Method agreement\n",
    "        ax2 = axes[0, 1]\n",
    "        colors = ['darkgreen' if a >= 3 else 'orange' if a >= 2 else 'lightcoral' \n",
    "                  for a in self.consensus['methods_top3']]\n",
    "        ax2.barh(self.consensus['feature'][::-1], self.consensus['methods_top3'][::-1], color=colors[::-1])\n",
    "        ax2.axvline(x=2, color='orange', linestyle='--', linewidth=2)\n",
    "        ax2.set_xlabel('Methods Ranking Feature in Top 3')\n",
    "        ax2.set_title('Method Agreement\\n(Green=3/3, Orange=2/3, Red=1/3 or less)')\n",
    "        \n",
    "        # 3. Average rank\n",
    "        ax3 = axes[1, 0]\n",
    "        colors = ['steelblue' if t == 'binary' else 'forestgreen' for t in self.consensus['type']]\n",
    "        ax3.barh(self.consensus['feature'][::-1], self.consensus['avg_rank'][::-1], color=colors[::-1])\n",
    "        ax3.set_xlabel('Average Rank (lower = better)')\n",
    "        ax3.set_title('Consensus Ranking\\n(Green=Continuous, Blue=Binary)')\n",
    "        ax3.invert_xaxis()\n",
    "        \n",
    "        # 4. Correlation vs VIP\n",
    "        ax4 = axes[1, 1]\n",
    "        for _, row in self.consensus.iterrows():\n",
    "            color = 'steelblue' if row['type'] == 'binary' else 'forestgreen'\n",
    "            marker = 's' if row['has_interaction'] else 'o'\n",
    "            ax4.scatter(abs(row['correlation']), row['VIP'], c=color, s=100, marker=marker, \n",
    "                        edgecolors='black', linewidth=0.5)\n",
    "            ax4.annotate(row['feature'], (abs(row['correlation']), row['VIP']), \n",
    "                         fontsize=8, ha='left', va='bottom')\n",
    "        \n",
    "        ax4.axhline(y=self.vip_important, color='green', linestyle='--', alpha=0.7, \n",
    "                    label=f'VIP={self.vip_important}')\n",
    "        ax4.axvline(x=self.correlation_strong, color='blue', linestyle='--', alpha=0.7, \n",
    "                    label=f'|r|={self.correlation_strong}')\n",
    "        ax4.set_xlabel('|Correlation|')\n",
    "        ax4.set_ylabel('VIP Score')\n",
    "        ax4.set_title('Correlation vs VIP\\n(Square=Has Interaction)')\n",
    "        ax4.legend(loc='lower right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_validation(self, loo_preds, loo_actual, metrics):\n",
    "        \"\"\"Plot LOO-CV validation results.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        \n",
    "        ax1 = axes[0]\n",
    "        ax1.scatter(loo_actual, loo_preds, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "        min_val, max_val = min(loo_actual.min(), loo_preds.min()), max(loo_actual.max(), loo_preds.max())\n",
    "        ax1.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect')\n",
    "        ax1.set_xlabel('Actual')\n",
    "        ax1.set_ylabel('Predicted')\n",
    "        ax1.set_title(f'LOO-CV: R² = {metrics[\"r2\"]:.4f}')\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2 = axes[1]\n",
    "        residuals = loo_actual - loo_preds\n",
    "        ax2.hist(residuals, bins=12, edgecolor='black', alpha=0.7)\n",
    "        ax2.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "        ax2.set_xlabel('Residual (Actual - Predicted)')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.set_title(f'Residuals: Mean={residuals.mean():.3f}')\n",
    "        \n",
    "        ax3 = axes[2]\n",
    "        ax3.scatter(loo_preds, residuals, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "        ax3.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "        ax3.set_xlabel('Predicted')\n",
    "        ax3.set_ylabel('Residual')\n",
    "        ax3.set_title('Residuals vs Predicted')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_all(self, results):\n",
    "        \"\"\"Generate all plots.\"\"\"\n",
    "        self.plot_feature_vs_response(results['X_train'], results['y_train'])\n",
    "        self.plot_response_distribution(results['y_train'])\n",
    "        self.plot_correlation(results['corr_df'])\n",
    "        self.plot_lasso(results['lasso_df'])\n",
    "        self.plot_pls(results['pls_df'], results['cv_scores'])\n",
    "        if len(results['interaction_df']) > 0:\n",
    "            self.plot_interactions(results['interaction_df'])\n",
    "        self.plot_multicollinearity(results['feature_corr'])\n",
    "        self.plot_consensus()\n",
    "        self.plot_validation(results['loo_preds'], results['loo_actual'], results['metrics'])\n",
    "    \n",
    "    # =========================================================================\n",
    "    # MAIN FIT METHOD\n",
    "    # =========================================================================\n",
    "    \n",
    "    def fit(self, df, feature_list, manual_features=None, verbose=True, plot=True):\n",
    "        \"\"\"\n",
    "        Run complete feature screening pipeline.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame - Input data\n",
    "        feature_list : list - List of feature column names\n",
    "        manual_features : list or None - If provided, override automatic selection\n",
    "        verbose : bool - Print detailed output\n",
    "        plot : bool - Generate plots\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        results : dict with all analysis results\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"=\" * 70)\n",
    "            print(\"PHASE 1: FEATURE SCREENING FOR BAYESIAN OPTIMIZATION\")\n",
    "            print(\"=\" * 70)\n",
    "        \n",
    "        # Classify and prepare\n",
    "        df = self.classify_features(df.copy(), feature_list, verbose)\n",
    "        X_train, X_test, X_train_model, X_test_model, y_train, y_test = self.prepare_data(df, verbose)\n",
    "        \n",
    "        # Run methods on training data only\n",
    "        corr_df = self.compute_correlations(X_train, y_train, verbose)\n",
    "        lasso_df, lasso_alpha = self.run_lasso(X_train_model, y_train, verbose)\n",
    "        pls_df, optimal_comp, cv_scores = self.run_pls(X_train_model, y_train, verbose)\n",
    "        interaction_df, strong_interactions, features_with_interactions = self.screen_interactions(\n",
    "            X_train, y_train, corr_df, verbose)\n",
    "        high_corr_pairs, feature_corr = self.check_multicollinearity(X_train, verbose)\n",
    "        \n",
    "        # Build consensus and recommend\n",
    "        self.build_consensus(corr_df, lasso_df, pls_df, verbose)\n",
    "        \n",
    "        # Feature selection: manual override or automatic\n",
    "        if manual_features is not None:\n",
    "            self.set_features_manual(manual_features, verbose)\n",
    "        else:\n",
    "            self.recommend_features(verbose)\n",
    "        \n",
    "        # Validate and generate bounds\n",
    "        metrics, loo_preds, loo_actual, issues = self.validate_selection(\n",
    "            X_train, X_train_model, y_train, verbose)\n",
    "        self.generate_bo_bounds(self.original_X_train, verbose)\n",
    "        \n",
    "        results = {\n",
    "            'corr_df': corr_df, 'lasso_df': lasso_df, 'pls_df': pls_df,\n",
    "            'interaction_df': interaction_df, 'strong_interactions': strong_interactions,\n",
    "            'features_with_interactions': features_with_interactions,\n",
    "            'high_corr_pairs': high_corr_pairs, 'feature_corr': feature_corr,\n",
    "            'consensus': self.consensus, 'selected_features': self.selected_features,\n",
    "            'metrics': metrics, 'loo_preds': loo_preds, 'loo_actual': loo_actual,\n",
    "            'validation_issues': issues,\n",
    "            'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test,\n",
    "            'X_train_model': X_train_model, 'X_test_model': X_test_model,\n",
    "            'lasso_alpha': lasso_alpha, 'pls_optimal_comp': optimal_comp, 'cv_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Plotting\n",
    "        if plot:\n",
    "            self.plot_all(results)\n",
    "        \n",
    "        # Final summary\n",
    "        if verbose:\n",
    "            self._print_final_summary(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def rerun_with_features(self, results, new_features, verbose=True, plot=True):\n",
    "        \"\"\"\n",
    "        Re-run validation with different feature selection.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        results : dict - Results from previous fit()\n",
    "        new_features : list - New list of features to use\n",
    "        verbose : bool - Print detailed output\n",
    "        plot : bool - Generate validation plot\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        Updated results dict\n",
    "        \"\"\"\n",
    "        self.set_features_manual(new_features, verbose)\n",
    "        \n",
    "        metrics, loo_preds, loo_actual, issues = self.validate_selection(\n",
    "            results['X_train'], results['X_train_model'], results['y_train'], verbose)\n",
    "        self.generate_bo_bounds(self.original_X_train, verbose)\n",
    "        \n",
    "        results['selected_features'] = self.selected_features\n",
    "        results['metrics'] = metrics\n",
    "        results['loo_preds'] = loo_preds\n",
    "        results['loo_actual'] = loo_actual\n",
    "        results['validation_issues'] = issues\n",
    "        \n",
    "        if plot:\n",
    "            self.plot_validation(loo_preds, loo_actual, metrics)\n",
    "        \n",
    "        if verbose:\n",
    "            self._print_final_summary(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _print_final_summary(self, results):\n",
    "        \"\"\"Print final summary.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"PHASE 1 COMPLETE: FEATURE SCREENING SUMMARY\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        print(f\"\"\"\n",
    "DATA:\n",
    "  Train samples: {len(results['X_train'])}\n",
    "  Test samples: {len(results['X_test'])}\n",
    "  Total features: {len(self.feature_cols)}\n",
    "    - Binary: {len(self.binary_features)}\n",
    "    - Continuous: {len(self.continuous_features)}\n",
    "\n",
    "METHODS USED:\n",
    "  1. Pearson Correlation\n",
    "  2. Lasso Regression (alpha={results['lasso_alpha']:.4f})\n",
    "  3. PLS with VIP Scores ({results['pls_optimal_comp']} components)\n",
    "  4. Interaction Screening\n",
    "  5. Multicollinearity Check\n",
    "\n",
    "SELECTED FOR BAYESIAN OPTIMIZATION ({len(self.selected_features)}):\n",
    "\"\"\")\n",
    "        \n",
    "        for feat in self.selected_features:\n",
    "            row = self.consensus[self.consensus['feature'] == feat].iloc[0]\n",
    "            bounds = self.bo_bounds_df[self.bo_bounds_df['feature'] == feat].iloc[0]\n",
    "            int_flag = \" ⚡\" if row['has_interaction'] else \"\"\n",
    "            print(f\"  • {feat} ({row['type']}){int_flag}\")\n",
    "            print(f\"      Correlation: {row['correlation']:+.3f}\")\n",
    "            print(f\"      VIP Score: {row['VIP']:.2f}\")\n",
    "            print(f\"      Bounds: [{bounds['min']:.2f}, {bounds['max']:.2f}]\")\n",
    "        \n",
    "        if self.features_with_interactions:\n",
    "            print(f\"\\n  ⚡ = Part of detected interaction\")\n",
    "        \n",
    "        if results['validation_issues']:\n",
    "            print(f\"\\n⚠️ VALIDATION ISSUES:\")\n",
    "            for issue in results['validation_issues']:\n",
    "                print(f\"    • {issue}\")\n",
    "        \n",
    "        print(f\"\"\"\n",
    "VALIDATION:\n",
    "  LOO-CV R²: {results['metrics']['r2']:.4f}\n",
    "  LOO-CV RMSE: {results['metrics']['rmse']:.4f}\n",
    "  LOO-CV MAE: {results['metrics']['mae']:.4f}\n",
    "\n",
    "NEXT STEPS (Phase 2: Bayesian Optimization):\n",
    "  1. Load bo_initial_data.csv as initial training data\n",
    "  2. Use bo_bounds.csv for search space\n",
    "  3. Fit GP surrogate model\n",
    "  4. Run acquisition function loop (EI or UCB)\n",
    "  5. Expected iterations: {20*len(self.selected_features)}-{40*len(self.selected_features)}\n",
    "\"\"\")\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"READY FOR PHASE 2: BAYESIAN OPTIMIZATION\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONVENIENCE FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def run_feature_screening(df, feature_list, response_column, target_features=4, \n",
    "                          maximize_response=False, test_size=0.2, \n",
    "                          manual_features=None, export=True, plot=True,\n",
    "                          verbose=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Convenience function to run complete feature screening.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame - Input data\n",
    "    feature_list : list - List of feature column names\n",
    "    response_column : str - Name of response variable\n",
    "    target_features : int - Number of features to select (default: 4)\n",
    "    maximize_response : bool - True if higher response is better (default: False)\n",
    "    test_size : float - Proportion for test set (default: 0.2)\n",
    "    manual_features : list or None - Override automatic selection with these features\n",
    "    export : bool - Whether to export CSV files (default: True)\n",
    "    plot : bool - Whether to generate plots (default: True)\n",
    "    verbose : bool - Whether to print detailed output (default: True)\n",
    "    **kwargs : Additional parameters for FeatureScreener thresholds:\n",
    "        - correlation_strong (default: 0.4)\n",
    "        - correlation_moderate (default: 0.2)\n",
    "        - vip_important (default: 1.0)\n",
    "        - vip_moderate (default: 0.8)\n",
    "        - multicollinearity_threshold (default: 0.7)\n",
    "        - interaction_threshold (default: 0.3)\n",
    "        - random_state (default: 42)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    screener : FeatureScreener object\n",
    "    results : dict with all analysis results\n",
    "    \n",
    "    Examples:\n",
    "    ---------\n",
    "    # Automatic selection\n",
    "    screener, results = run_feature_screening(\n",
    "        df=df_total,\n",
    "        feature_list=feature_list,\n",
    "        response_column=\"Downy Leak\",\n",
    "        target_features=4\n",
    "    )\n",
    "    \n",
    "    # Manual override\n",
    "    screener, results = run_feature_screening(\n",
    "        df=df_total,\n",
    "        feature_list=feature_list,\n",
    "        response_column=\"Downy Leak\",\n",
    "        manual_features=['Feature_A', 'Feature_B', 'Feature_C']\n",
    "    )\n",
    "    \n",
    "    # Re-run with different features after initial fit\n",
    "    results = screener.rerun_with_features(results, ['New_Feature_1', 'New_Feature_2'])\n",
    "    \"\"\"\n",
    "    screener = FeatureScreener(\n",
    "        response_column=response_column,\n",
    "        target_features=target_features,\n",
    "        maximize_response=maximize_response,\n",
    "        test_size=test_size,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    results = screener.fit(df, feature_list, manual_features=manual_features, \n",
    "                           verbose=verbose, plot=plot)\n",
    "    \n",
    "    if export:\n",
    "        # Combine train and test for export\n",
    "        original_X = pd.concat([screener.original_X_train, screener.original_X_test]).reset_index(drop=True)\n",
    "        original_y = pd.concat([screener.original_y_train, screener.original_y_test]).reset_index(drop=True)\n",
    "        screener.export_for_bo(original_X, original_y, verbose=verbose)\n",
    "    \n",
    "    return screener, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8344b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Cells 1-6 (data loading and configuration)\n",
    "\n",
    "screener, results = run_feature_screening(\n",
    "    df=df_total,\n",
    "    feature_list=feature_list,\n",
    "    response_column=RESPONSE_COLUMN,\n",
    "    target_features=TARGET_FEATURES,\n",
    "    maximize_response=MAXIMIZE_RESPONSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc518bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "screener, results = run_feature_screening(\n",
    "    df=df_total,\n",
    "    feature_list=feature_list,\n",
    "    response_column=RESPONSE_COLUMN,\n",
    "    manual_features=['example']  # Your chosen features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run automatic to see recommendations\n",
    "screener, results = run_feature_screening(\n",
    "    df=df_total,\n",
    "    feature_list=feature_list,\n",
    "    response_column=RESPONSE_COLUMN,\n",
    "    target_features=4,\n",
    "    export=False  # Don't export yet\n",
    ")\n",
    "\n",
    "# Review results, then manually select different features\n",
    "results = screener.rerun_with_features(\n",
    "    results, \n",
    "    new_features=['Feature_A', 'Feature_B', 'Feature_C', 'Feature_D']\n",
    ")\n",
    "\n",
    "# Now export with your manual selection\n",
    "original_X = pd.concat([screener.original_X_train, screener.original_X_test]).reset_index(drop=True)\n",
    "original_y = pd.concat([screener.original_y_train, screener.original_y_test]).reset_index(drop=True)\n",
    "screener.export_for_bo(original_X, original_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbffa68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quiet Mode\n",
    "screener, results = run_feature_screening(\n",
    "    df=df_total,\n",
    "    feature_list=feature_list,\n",
    "    response_column=RESPONSE_COLUMN,\n",
    "    target_features=4,\n",
    "    verbose=False,\n",
    "    plot=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "screener, results = run_feature_screening(\n",
    "    df=df_total,\n",
    "    feature_list=feature_list,\n",
    "    response_column=RESPONSE_COLUMN,\n",
    "    target_features=4,\n",
    "    correlation_strong=0.5,        # Stricter correlation threshold\n",
    "    correlation_moderate=0.3,\n",
    "    vip_important=1.2,             # Stricter VIP threshold\n",
    "    vip_moderate=0.9,\n",
    "    multicollinearity_threshold=0.6,  # Stricter multicollinearity\n",
    "    interaction_threshold=0.4,\n",
    "    test_size=0.25                 # Larger test set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de24866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access results: \n",
    "# Selected features\n",
    "print(screener.selected_features)\n",
    "\n",
    "# BO bounds\n",
    "print(screener.bo_bounds_df)\n",
    "\n",
    "# Consensus ranking\n",
    "print(results['consensus'])\n",
    "\n",
    "# Validation metrics\n",
    "print(f\"LOO R²: {results['metrics']['r2']:.4f}\")\n",
    "\n",
    "# Features with interactions\n",
    "print(screener.features_with_interactions)\n",
    "\n",
    "# Binary feature mappings\n",
    "print(screener.binary_mappings)\n",
    "\n",
    "# Check for validation issues\n",
    "if results['validation_issues']:\n",
    "    print(\"Issues found:\", results['validation_issues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate individual pllots\n",
    "# Run without plots first\n",
    "screener, results = run_feature_screening(\n",
    "    df=df_total,\n",
    "    feature_list=feature_list,\n",
    "    response_column=RESPONSE_COLUMN,\n",
    "    plot=False\n",
    ")\n",
    "\n",
    "# Then generate specific plots as needed\n",
    "screener.plot_correlation(results['corr_df'])\n",
    "screener.plot_lasso(results['lasso_df'])\n",
    "screener.plot_pls(results['pls_df'], results['cv_scores'])\n",
    "screener.plot_consensus()\n",
    "screener.plot_validation(results['loo_preds'], results['loo_actual'], results['metrics'])\n",
    "\n",
    "# Or generate all plots at once\n",
    "screener.plot_all(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfeba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Run initial screening\n",
    "screener, results = run_feature_screening(\n",
    "    df=df_total,\n",
    "    feature_list=feature_list,\n",
    "    response_column=RESPONSE_COLUMN,\n",
    "    target_features=5,\n",
    "    export=False\n",
    ")\n",
    "\n",
    "# Step 2: View consensus to decide\n",
    "print(\"\\nConsensus ranking:\")\n",
    "print(results['consensus'][['feature', 'correlation', 'VIP', 'selected', 'score']])\n",
    "\n",
    "# Step 3: Try different combinations\n",
    "print(\"\\n--- Trying combination 1 ---\")\n",
    "results = screener.rerun_with_features(results, ['Feat_A', 'Feat_B', 'Feat_C'], plot=False)\n",
    "print(f\"R² = {results['metrics']['r2']:.4f}\")\n",
    "\n",
    "print(\"\\n--- Trying combination 2 ---\")\n",
    "results = screener.rerun_with_features(results, ['Feat_A', 'Feat_D', 'Feat_E'], plot=False)\n",
    "print(f\"R² = {results['metrics']['r2']:.4f}\")\n",
    "\n",
    "# Step 4: Finalize with best combination\n",
    "results = screener.rerun_with_features(results, ['Feat_A', 'Feat_B', 'Feat_C'], plot=True)\n",
    "\n",
    "# Step 5: Export\n",
    "original_X = pd.concat([screener.original_X_train, screener.original_X_test]).reset_index(drop=True)\n",
    "original_y = pd.concat([screener.original_y_train, screener.original_y_test]).reset_index(drop=True)\n",
    "screener.export_for_bo(original_X, original_y)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
