{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bayesian Optimization Pipeline - Modular Implementation\n",
    "========================================================\n",
    "Phase 1: Feature Selection and Screening\n",
    "Phase 2: Bayesian Optimization\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple, Any, Union\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel, Matern\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from itertools import combinations\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377957ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Configuration Classes\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "@dataclass\n",
    "class Phase1Config:\n",
    "    \"\"\"Configuration for Phase 1: Feature Selection.\"\"\"\n",
    "    data_file: str\n",
    "    response_column: str\n",
    "    sheet_name: str = 'data'\n",
    "    header_row: int = 5\n",
    "    split_keyword: Optional[str] = \"PREDICTED OPTIMUM RUNS\"\n",
    "    stop_feature: Optional[str] = \"Batch ID\"\n",
    "    maximize_response: bool = False\n",
    "    target_features: int = 4\n",
    "    output_dir: str = 'bo_pipeline_output'\n",
    "    \n",
    "    # Thresholds\n",
    "    correlation_strong: float = 0.4\n",
    "    correlation_moderate: float = 0.2\n",
    "    vip_important: float = 1.0\n",
    "    vip_moderate: float = 0.8\n",
    "    multicollinearity_threshold: float = 0.7\n",
    "    interaction_threshold: float = 0.3\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Phase2Config:\n",
    "    \"\"\"Configuration for Phase 2: Bayesian Optimization.\"\"\"\n",
    "    data_file: str\n",
    "    checkpoint_path: str\n",
    "    batch_size: int = 5\n",
    "    exploration_weight: float = 2.0\n",
    "    n_optimizer_restarts: int = 20\n",
    "    min_distance_between_points: float = 0.3\n",
    "    max_iterations: int = 10\n",
    "    improvement_threshold: float = 0.01\n",
    "    patience: int = 3\n",
    "    output_dir: str = 'bo_pipeline_output'\n",
    "    sheet_name: str = 'Sheet1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad98e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# DataLoader Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Handles data loading, cleaning, and feature classification.\"\"\"\n",
    "    \n",
    "    def load_excel(self, file_path: str, sheet_name: str, header_row: int) -> pd.DataFrame:\n",
    "        \"\"\"Load Excel file and return DataFrame.\"\"\"\n",
    "        xls = pd.ExcelFile(file_path, engine='openpyxl')\n",
    "        df = pd.read_excel(xls, sheet_name=sheet_name, header=header_row)\n",
    "        return df\n",
    "    \n",
    "    def split_at_keyword(self, df: pd.DataFrame, keyword: str, \n",
    "                         column: str = 'Run') -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Split DataFrame at keyword row.\"\"\"\n",
    "        split_index = df.index[df[column] == keyword].tolist()\n",
    "        \n",
    "        if split_index:\n",
    "            idx = split_index[0]\n",
    "            df_initial = df.iloc[:idx]\n",
    "            df_optimum = df.iloc[idx+1:]\n",
    "            return df_initial, df_optimum\n",
    "        return df.copy(), pd.DataFrame()\n",
    "    \n",
    "    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Clean DataFrame by removing empty rows and resetting index.\"\"\"\n",
    "        df = df.drop(index=0, errors='ignore')\n",
    "        df = df.dropna(how='all')\n",
    "        return df.reset_index(drop=True)\n",
    "    \n",
    "    def classify_features(self, df: pd.DataFrame, feature_cols: List[str]\n",
    "                         ) -> Tuple[List[str], List[str], Dict]:\n",
    "        \"\"\"\n",
    "        Classify features as binary or continuous.\n",
    "        \n",
    "        Returns:\n",
    "            binary_list: List of binary feature names\n",
    "            continuous_list: List of continuous feature names\n",
    "            mappings: Dictionary of binary feature value mappings\n",
    "        \"\"\"\n",
    "        numeric_features = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        binary_cols = []\n",
    "        continuous_cols = []\n",
    "        binary_mappings = {}\n",
    "        \n",
    "        for col in numeric_features:\n",
    "            n_unique = df[col].nunique()\n",
    "            \n",
    "            if n_unique == 2:\n",
    "                binary_cols.append(col)\n",
    "                unique_vals = sorted(df[col].dropna().unique())\n",
    "                mapping = {unique_vals[0]: 0, unique_vals[1]: 1}\n",
    "                df[col] = df[col].map(mapping)\n",
    "                binary_mappings[col] = mapping\n",
    "            else:\n",
    "                continuous_cols.append(col)\n",
    "        \n",
    "        return binary_cols, continuous_cols, binary_mappings\n",
    "    \n",
    "    def get_feature_columns(self, df: pd.DataFrame, stop_feature: Optional[str], \n",
    "                           response_column: str) -> List[str]:\n",
    "        \"\"\"Extract feature column names.\"\"\"\n",
    "        columns = df.columns.tolist()\n",
    "        \n",
    "        if stop_feature and stop_feature in columns:\n",
    "            feature_list = columns[:columns.index(stop_feature)]\n",
    "        else:\n",
    "            feature_list = [c for c in columns if c != response_column]\n",
    "        \n",
    "        # Remove index-like columns\n",
    "        feature_list = [f for f in feature_list if f.lower() not in ['run', 'index', 'unnamed: 0']]\n",
    "        return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a771f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# FeatureRanker Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class FeatureRanker:\n",
    "    \"\"\"Performs feature ranking using multiple methods.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Phase1Config):\n",
    "        self.config = config\n",
    "        self._corr_df = None\n",
    "        self._lasso_df = None\n",
    "        self._pls_df = None\n",
    "        self._interaction_df = None\n",
    "        self._multicollinearity_pairs = []\n",
    "        self._features_with_interactions = []\n",
    "        self._optimal_pls_components = None\n",
    "    \n",
    "    def run_correlation(self, X: pd.DataFrame, y: pd.Series, \n",
    "                       binary_features: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Compute Pearson correlation rankings.\"\"\"\n",
    "        correlations = X.corrwith(y)\n",
    "        \n",
    "        self._corr_df = pd.DataFrame({\n",
    "            'feature': X.columns.tolist(),\n",
    "            'correlation': correlations.values,\n",
    "            'abs_corr': np.abs(correlations.values),\n",
    "            'type': ['binary' if f in binary_features else 'continuous' for f in X.columns],\n",
    "            'direction': ['Positive' if c > 0 else 'Negative' for c in correlations.values]\n",
    "        }).sort_values('abs_corr', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        self._corr_df['rank_corr'] = range(1, len(self._corr_df) + 1)\n",
    "        self._corr_df['strength'] = self._corr_df['correlation'].apply(self._corr_strength)\n",
    "        \n",
    "        return self._corr_df\n",
    "    \n",
    "    def _corr_strength(self, r: float) -> str:\n",
    "        if abs(r) >= self.config.correlation_strong: return 'Strong'\n",
    "        elif abs(r) >= self.config.correlation_moderate: return 'Moderate'\n",
    "        return 'Weak'\n",
    "    \n",
    "    def run_lasso(self, X: pd.DataFrame, y: pd.Series, \n",
    "                  binary_features: List[str]) -> Tuple[pd.DataFrame, List[str]]:\n",
    "        \"\"\"Run Lasso regression for feature selection.\"\"\"\n",
    "        X_model = self._prepare_for_modeling(X, binary_features)\n",
    "        \n",
    "        lasso = LassoCV(cv=5, max_iter=10000, random_state=RANDOM_STATE)\n",
    "        lasso.fit(X_model, y)\n",
    "        \n",
    "        self._lasso_df = pd.DataFrame({\n",
    "            'feature': X.columns.tolist(),\n",
    "            'coefficient': lasso.coef_,\n",
    "            'abs_coef': np.abs(lasso.coef_),\n",
    "            'selected': lasso.coef_ != 0,\n",
    "            'type': ['binary' if f in binary_features else 'continuous' for f in X.columns]\n",
    "        }).sort_values('abs_coef', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        self._lasso_df['rank_lasso'] = range(1, len(self._lasso_df) + 1)\n",
    "        selected_features = self._lasso_df[self._lasso_df['selected']]['feature'].tolist()\n",
    "        \n",
    "        return self._lasso_df, selected_features\n",
    "    \n",
    "    def run_pls_vip(self, X: pd.DataFrame, y: pd.Series, \n",
    "                    binary_features: List[str]) -> Tuple[pd.DataFrame, int]:\n",
    "        \"\"\"Run PLS regression and compute VIP scores.\"\"\"\n",
    "        X_model = self._prepare_for_modeling(X, binary_features)\n",
    "        \n",
    "        max_comp = min(5, len(X.columns), len(X) - 1)\n",
    "        cv_scores = []\n",
    "        \n",
    "        for n in range(1, max_comp + 1):\n",
    "            scores = cross_val_score(PLSRegression(n_components=n), X_model, y, cv=5, scoring='r2')\n",
    "            cv_scores.append(scores.mean())\n",
    "        \n",
    "        self._optimal_pls_components = np.argmax(cv_scores) + 1\n",
    "        \n",
    "        pls = PLSRegression(n_components=self._optimal_pls_components)\n",
    "        pls.fit(X_model, y)\n",
    "        vip_scores = self._calc_vip(pls)\n",
    "        \n",
    "        self._pls_df = pd.DataFrame({\n",
    "            'feature': X.columns.tolist(),\n",
    "            'VIP': vip_scores,\n",
    "            'type': ['binary' if f in binary_features else 'continuous' for f in X.columns]\n",
    "        }).sort_values('VIP', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        self._pls_df['rank_pls'] = range(1, len(self._pls_df) + 1)\n",
    "        self._pls_df['category'] = self._pls_df['VIP'].apply(self._vip_category)\n",
    "        \n",
    "        return self._pls_df, self._optimal_pls_components\n",
    "    \n",
    "    def _calc_vip(self, model) -> np.ndarray:\n",
    "        \"\"\"Calculate VIP scores for PLS model.\"\"\"\n",
    "        t, w, q = model.x_scores_, model.x_weights_, model.y_loadings_\n",
    "        m, p = w.shape\n",
    "        ss = np.sum(t**2, axis=0) * q.flatten()**2\n",
    "        total_ss = np.sum(ss)\n",
    "        vip = np.zeros(m)\n",
    "        for i in range(m):\n",
    "            weight = sum((w[i,j]**2) * ss[j] / np.sum(w[:,j]**2) for j in range(p))\n",
    "            vip[i] = np.sqrt(m * weight / total_ss)\n",
    "        return vip\n",
    "    \n",
    "    def _vip_category(self, v: float) -> str:\n",
    "        if v >= self.config.vip_important: return 'Important'\n",
    "        elif v >= self.config.vip_moderate: return 'Moderate'\n",
    "        return 'Less Important'\n",
    "    \n",
    "    def _prepare_for_modeling(self, X: pd.DataFrame, binary_features: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Scale continuous features and encode binary as [-1, +1].\"\"\"\n",
    "        X_model = X.copy()\n",
    "        continuous = [c for c in X.columns if c not in binary_features]\n",
    "        \n",
    "        if continuous:\n",
    "            scaler = StandardScaler()\n",
    "            X_model[continuous] = scaler.fit_transform(X[continuous])\n",
    "        \n",
    "        for col in binary_features:\n",
    "            if col in X_model.columns:\n",
    "                X_model[col] = X_model[col] * 2 - 1\n",
    "        \n",
    "        return X_model\n",
    "    \n",
    "    def run_interaction_screening(self, X: pd.DataFrame, y: pd.Series, \n",
    "                                   top_n: int = 6) -> pd.DataFrame:\n",
    "        \"\"\"Screen for feature interactions.\"\"\"\n",
    "        if self._corr_df is None:\n",
    "            raise ValueError(\"Run correlation analysis first\")\n",
    "        \n",
    "        top_features = self._corr_df.head(min(top_n, len(X.columns)))['feature'].tolist()\n",
    "        results = []\n",
    "        \n",
    "        for f1, f2 in combinations(top_features, 2):\n",
    "            median_f2 = X[f2].median()\n",
    "            low_f2 = X[f2] <= median_f2\n",
    "            high_f2 = X[f2] > median_f2\n",
    "            \n",
    "            if low_f2.sum() >= 3 and high_f2.sum() >= 3:\n",
    "                corr_low = X.loc[low_f2, f1].corr(y[low_f2])\n",
    "                corr_high = X.loc[high_f2, f1].corr(y[high_f2])\n",
    "                \n",
    "                if not np.isnan(corr_low) and not np.isnan(corr_high):\n",
    "                    strength = abs(corr_high - corr_low)\n",
    "                    results.append({\n",
    "                        'interaction': f'{f1} × {f2}',\n",
    "                        'feature_1': f1, 'feature_2': f2,\n",
    "                        'corr_low_f2': corr_low, 'corr_high_f2': corr_high,\n",
    "                        'strength': strength,\n",
    "                        'significant': strength > self.config.interaction_threshold\n",
    "                    })\n",
    "        \n",
    "        if results:\n",
    "            self._interaction_df = pd.DataFrame(results).sort_values('strength', ascending=False)\n",
    "            strong = self._interaction_df[self._interaction_df['significant']]\n",
    "            self._features_with_interactions = list(set(\n",
    "                strong['feature_1'].tolist() + strong['feature_2'].tolist()\n",
    "            ))\n",
    "        else:\n",
    "            self._interaction_df = pd.DataFrame()\n",
    "            self._features_with_interactions = []\n",
    "        \n",
    "        return self._interaction_df\n",
    "    \n",
    "    def check_multicollinearity(self, X: pd.DataFrame, \n",
    "                                 threshold: Optional[float] = None) -> List[Dict]:\n",
    "        \"\"\"Check for highly correlated feature pairs.\"\"\"\n",
    "        threshold = threshold or self.config.multicollinearity_threshold\n",
    "        feature_corr = X.corr()\n",
    "        pairs = []\n",
    "        \n",
    "        for i in range(len(X.columns)):\n",
    "            for j in range(i+1, len(X.columns)):\n",
    "                r = feature_corr.iloc[i, j]\n",
    "                if abs(r) > threshold:\n",
    "                    pairs.append({\n",
    "                        'feature_1': X.columns[i],\n",
    "                        'feature_2': X.columns[j],\n",
    "                        'correlation': r\n",
    "                    })\n",
    "        \n",
    "        self._multicollinearity_pairs = pairs\n",
    "        return pairs\n",
    "    \n",
    "    def get_consensus_ranking(self) -> pd.DataFrame:\n",
    "        \"\"\"Combine all ranking methods into consensus ranking.\"\"\"\n",
    "        if any(df is None for df in [self._corr_df, self._lasso_df, self._pls_df]):\n",
    "            raise ValueError(\"Run all ranking methods first\")\n",
    "        \n",
    "        consensus = self._corr_df[['feature', 'rank_corr', 'correlation', 'direction', \n",
    "                                    'type', 'strength']].merge(\n",
    "            self._lasso_df[['feature', 'rank_lasso', 'coefficient', 'selected']], on='feature'\n",
    "        ).merge(\n",
    "            self._pls_df[['feature', 'rank_pls', 'VIP', 'category']], on='feature'\n",
    "        )\n",
    "        \n",
    "        consensus['avg_rank'] = consensus[['rank_corr', 'rank_lasso', 'rank_pls']].mean(axis=1)\n",
    "        consensus = consensus.sort_values('avg_rank').reset_index(drop=True)\n",
    "        consensus['final_rank'] = range(1, len(consensus) + 1)\n",
    "        consensus['methods_top3'] = consensus.apply(\n",
    "            lambda r: sum([r['rank_corr'] <= 3, r['rank_lasso'] <= 3, r['rank_pls'] <= 3]), axis=1\n",
    "        )\n",
    "        consensus['has_interaction'] = consensus['feature'].isin(self._features_with_interactions)\n",
    "        \n",
    "        return consensus\n",
    "    \n",
    "    @property\n",
    "    def features_with_interactions(self) -> List[str]:\n",
    "        return self._features_with_interactions\n",
    "    \n",
    "    @property\n",
    "    def multicollinearity_pairs(self) -> List[Dict]:\n",
    "        return self._multicollinearity_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23db89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# FeatureSelector Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class FeatureSelector:\n",
    "    \"\"\"Handles automatic and manual feature selection with validation.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Phase1Config, ranker: FeatureRanker):\n",
    "        self.config = config\n",
    "        self.ranker = ranker\n",
    "        self._consensus = None\n",
    "        self._selected_features = []\n",
    "    \n",
    "    def auto_select(self, n_features: Optional[int] = None) -> List[str]:\n",
    "        \"\"\"Automatically select top features based on scoring.\"\"\"\n",
    "        n_features = n_features or self.config.target_features\n",
    "        self._consensus = self.ranker.get_consensus_ranking()\n",
    "        \n",
    "        # Score each feature\n",
    "        self._consensus['score'] = self._consensus.apply(self._score_feature, axis=1)\n",
    "        self._consensus = self._consensus.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        # Select top features\n",
    "        recommended = []\n",
    "        for _, row in self._consensus.iterrows():\n",
    "            include = False\n",
    "            if row['score'] >= 6: include = True\n",
    "            if abs(row['correlation']) >= self.config.correlation_strong: include = True\n",
    "            if row['VIP'] >= self.config.vip_important: include = True\n",
    "            if row['has_interaction'] and row['score'] >= 4: include = True\n",
    "            \n",
    "            if include and len(recommended) < 6:\n",
    "                recommended.append(row['feature'])\n",
    "        \n",
    "        # Ensure minimum\n",
    "        if len(recommended) < 3:\n",
    "            for _, row in self._consensus.iterrows():\n",
    "                if row['feature'] not in recommended:\n",
    "                    recommended.append(row['feature'])\n",
    "                if len(recommended) >= 3:\n",
    "                    break\n",
    "        \n",
    "        self._selected_features = recommended[:n_features]\n",
    "        return self._selected_features\n",
    "    \n",
    "    def _score_feature(self, row: pd.Series) -> int:\n",
    "        score = 0\n",
    "        if abs(row['correlation']) >= self.config.correlation_strong: score += 3\n",
    "        elif abs(row['correlation']) >= self.config.correlation_moderate: score += 2\n",
    "        if row['VIP'] >= self.config.vip_important: score += 3\n",
    "        elif row['VIP'] >= self.config.vip_moderate: score += 2\n",
    "        if row['selected']: score += 2\n",
    "        score += row['methods_top3']\n",
    "        if row['has_interaction']: score += 2\n",
    "        return score\n",
    "    \n",
    "    def manual_override(self, feature_list: List[str], \n",
    "                        all_features: List[str]) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Validate and apply manual feature selection.\"\"\"\n",
    "        warnings = []\n",
    "        validated = []\n",
    "        \n",
    "        for feat in feature_list:\n",
    "            if feat in all_features:\n",
    "                validated.append(feat)\n",
    "            else:\n",
    "                warnings.append(f\"⚠ Feature '{feat}' not found in available features\")\n",
    "        \n",
    "        if not validated:\n",
    "            warnings.append(\"⚠ No valid features provided\")\n",
    "        \n",
    "        self._selected_features = validated\n",
    "        return validated, warnings\n",
    "    \n",
    "    def validate_selection(self, X: pd.DataFrame, y: pd.Series, features: List[str],\n",
    "                           binary_features: List[str], continuous_features: List[str]\n",
    "                          ) -> Dict[str, float]:\n",
    "        \"\"\"Validate feature selection with leakage-free LOO-CV.\"\"\"\n",
    "        X_sel = X[features].copy()\n",
    "        sel_continuous = [f for f in features if f in continuous_features]\n",
    "        sel_binary = [f for f in features if f in binary_features]\n",
    "        \n",
    "        loo_preds, loo_actual = [], []\n",
    "        \n",
    "        for train_idx, test_idx in LeaveOneOut().split(X_sel):\n",
    "            X_train = X_sel.iloc[train_idx].copy()\n",
    "            X_test = X_sel.iloc[test_idx].copy()\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            \n",
    "            # Scale only on training data\n",
    "            if sel_continuous:\n",
    "                scaler = StandardScaler()\n",
    "                X_train[sel_continuous] = scaler.fit_transform(X_train[sel_continuous])\n",
    "                X_test[sel_continuous] = scaler.transform(X_test[sel_continuous])\n",
    "            \n",
    "            for col in sel_binary:\n",
    "                X_train[col] = X_train[col] * 2 - 1\n",
    "                X_test[col] = X_test[col] * 2 - 1\n",
    "            \n",
    "            model = RidgeCV(alphas=[0.1, 1, 10, 100], cv=3)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            loo_preds.append(model.predict(X_test)[0])\n",
    "            loo_actual.append(y_test.values[0])\n",
    "        \n",
    "        loo_preds = np.array(loo_preds)\n",
    "        loo_actual = np.array(loo_actual)\n",
    "        \n",
    "        return {\n",
    "            'r2': r2_score(loo_actual, loo_preds),\n",
    "            'rmse': np.sqrt(mean_squared_error(loo_actual, loo_preds)),\n",
    "            'mae': np.mean(np.abs(loo_actual - loo_preds))\n",
    "        }\n",
    "    \n",
    "    def check_selection_issues(self, X: pd.DataFrame, features: List[str]\n",
    "                               ) -> Dict[str, List]:\n",
    "        \"\"\"Check for multicollinearity and broken interactions in selection.\"\"\"\n",
    "        issues = {'multicollinearity': [], 'broken_interactions': []}\n",
    "        \n",
    "        if len(features) > 1:\n",
    "            sel_corr = X[features].corr()\n",
    "            for i in range(len(features)):\n",
    "                for j in range(i+1, len(features)):\n",
    "                    r = sel_corr.iloc[i, j]\n",
    "                    if abs(r) > self.config.multicollinearity_threshold:\n",
    "                        issues['multicollinearity'].append(\n",
    "                            f\"{features[i]} ↔ {features[j]}: r={r:.2f}\"\n",
    "                        )\n",
    "        \n",
    "        # Check broken interactions\n",
    "        if hasattr(self.ranker, '_interaction_df') and len(self.ranker._interaction_df) > 0:\n",
    "            strong = self.ranker._interaction_df[self.ranker._interaction_df['significant']]\n",
    "            for _, row in strong.iterrows():\n",
    "                f1, f2 = row['feature_1'], row['feature_2']\n",
    "                if (f1 in features) != (f2 in features):\n",
    "                    in1 = \"IN\" if f1 in features else \"OUT\"\n",
    "                    in2 = \"IN\" if f2 in features else \"OUT\"\n",
    "                    issues['broken_interactions'].append(f\"{f1} ({in1}) × {f2} ({in2})\")\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    @property\n",
    "    def selected_features(self) -> List[str]:\n",
    "        return self._selected_features\n",
    "    \n",
    "    @property\n",
    "    def consensus(self) -> pd.DataFrame:\n",
    "        return self._consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07430788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Phase1Checkpoint Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class Phase1Checkpoint:\n",
    "    \"\"\"Handles saving and loading Phase 1 results.\"\"\"\n",
    "    \n",
    "    def save(self, output_dir: str, results_dict: Dict[str, Any]) -> None:\n",
    "        \"\"\"Save checkpoint to disk.\"\"\"\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save JSON (human-readable)\n",
    "        with open(output_path / 'phase1_checkpoint.json', 'w') as f:\n",
    "            json.dump(results_dict, f, indent=2, default=str)\n",
    "        \n",
    "        # Save pickle (preserves all objects)\n",
    "        with open(output_path / 'phase1_checkpoint.pkl', 'wb') as f:\n",
    "            pickle.dump(results_dict, f)\n",
    "        \n",
    "        print(f\"✓ Checkpoint saved to {output_path}\")\n",
    "    \n",
    "    def load(self, checkpoint_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"Load checkpoint from disk.\"\"\"\n",
    "        path = Path(checkpoint_path)\n",
    "        \n",
    "        if path.suffix == '.pkl':\n",
    "            with open(path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            with open(path, 'r') as f:\n",
    "                return json.load(f)\n",
    "    \n",
    "    def export_bounds(self, features: List[str], X: pd.DataFrame, \n",
    "                      binary_features: List[str], margin: float = 0.1) -> pd.DataFrame:\n",
    "        \"\"\"Export search space bounds for selected features.\"\"\"\n",
    "        bounds = []\n",
    "        \n",
    "        for feat in features:\n",
    "            if feat in binary_features:\n",
    "                bounds.append({\n",
    "                    'feature': feat, 'type': 'binary',\n",
    "                    'min': 0, 'max': 1,\n",
    "                    'observed_min': 0, 'observed_max': 1\n",
    "                })\n",
    "            else:\n",
    "                feat_min, feat_max = X[feat].min(), X[feat].max()\n",
    "                feat_range = feat_max - feat_min\n",
    "                bounds.append({\n",
    "                    'feature': feat, 'type': 'continuous',\n",
    "                    'min': round(feat_min - margin * feat_range, 4),\n",
    "                    'max': round(feat_max + margin * feat_range, 4),\n",
    "                    'observed_min': feat_min, 'observed_max': feat_max\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Phase1Plotter Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class Phase1Plotter:\n",
    "    \"\"\"Plotting utilities for Phase 1 analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    def _save_and_show(self, fig, filename: str, save_path: Optional[str] = None):\n",
    "        path = save_path or (self.output_dir / filename)\n",
    "        plt.savefig(path, dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        return fig\n",
    "    \n",
    "    def scatter_plots(self, X: pd.DataFrame, y: pd.Series, binary_features: List[str],\n",
    "                      response_name: str, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot feature vs response scatter plots.\"\"\"\n",
    "        n_feat = len(X.columns)\n",
    "        n_cols = min(4, n_feat)\n",
    "        n_rows = int(np.ceil(n_feat / n_cols))\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 3.5*n_rows))\n",
    "        axes = axes.flatten() if n_feat > 1 else [axes]\n",
    "        \n",
    "        for i, col in enumerate(X.columns):\n",
    "            ax = axes[i]\n",
    "            corr = X[col].corr(y)\n",
    "            \n",
    "            if col in binary_features:\n",
    "                for val in [0, 1]:\n",
    "                    data = y[X[col] == val]\n",
    "                    if len(data) > 0:\n",
    "                        ax.boxplot([data], positions=[val], widths=0.6)\n",
    "                ax.set_xticks([0, 1])\n",
    "                ax.set_xlabel(f'{col} (binary)')\n",
    "            else:\n",
    "                ax.scatter(X[col], y, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "                z = np.polyfit(X[col], y, 1)\n",
    "                p = np.poly1d(z)\n",
    "                x_line = np.linspace(X[col].min(), X[col].max(), 100)\n",
    "                ax.plot(x_line, p(x_line), 'r--', linewidth=2)\n",
    "                ax.set_xlabel(col)\n",
    "            \n",
    "            ax.set_ylabel(response_name)\n",
    "            ax.set_title(f'r = {corr:.3f}', fontsize=10)\n",
    "        \n",
    "        for j in range(i+1, len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.suptitle(f'Features vs {response_name}', fontsize=12, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        return self._save_and_show(fig, 'phase1_scatter_plots.png', save_path)\n",
    "    \n",
    "    def correlation_plot(self, corr_df: pd.DataFrame, config: Phase1Config,\n",
    "                         save_path: Optional[str] = None):\n",
    "        \"\"\"Plot correlation analysis results.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        colors = ['forestgreen' if c > 0 else 'crimson' for c in corr_df['correlation']]\n",
    "        axes[0].barh(corr_df['feature'][::-1], corr_df['abs_corr'][::-1], color=colors[::-1])\n",
    "        axes[0].axvline(x=config.correlation_strong, color='green', linestyle='--', \n",
    "                       linewidth=2, label=f'Strong ({config.correlation_strong})')\n",
    "        axes[0].axvline(x=config.correlation_moderate, color='orange', linestyle='--', \n",
    "                       linewidth=1.5, label=f'Moderate ({config.correlation_moderate})')\n",
    "        axes[0].set_xlabel('|Correlation|')\n",
    "        axes[0].set_title('Feature-Response Correlation')\n",
    "        axes[0].legend(loc='lower right')\n",
    "        \n",
    "        axes[1].barh(corr_df['feature'][::-1], corr_df['correlation'][::-1], color=colors[::-1])\n",
    "        axes[1].axvline(x=0, color='black', linewidth=1)\n",
    "        axes[1].set_xlabel('Correlation (with sign)')\n",
    "        axes[1].set_title('Direction of Effect')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return self._save_and_show(fig, 'phase1_correlation_analysis.png', save_path)\n",
    "    \n",
    "    def lasso_plot(self, lasso_df: pd.DataFrame, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot Lasso regression results.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        colors = ['forestgreen' if s else 'lightgray' for s in lasso_df['selected']]\n",
    "        ax.barh(lasso_df['feature'][::-1], lasso_df['abs_coef'][::-1], color=colors[::-1])\n",
    "        ax.set_xlabel('|Coefficient|')\n",
    "        ax.set_title('Lasso Coefficients (Green = Selected)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return self._save_and_show(fig, 'phase1_lasso_analysis.png', save_path)\n",
    "    \n",
    "    def pls_plot(self, pls_df: pd.DataFrame, config: Phase1Config, \n",
    "                 cv_scores: List[float] = None, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot PLS VIP scores.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        colors = ['darkgreen' if v >= config.vip_important else \n",
    "                 'orange' if v >= config.vip_moderate else 'lightcoral' \n",
    "                 for v in pls_df['VIP']]\n",
    "        axes[0].barh(pls_df['feature'][::-1], pls_df['VIP'][::-1], color=colors[::-1])\n",
    "        axes[0].axvline(x=config.vip_important, color='green', linestyle='--', \n",
    "                       linewidth=2, label=f'Important ({config.vip_important})')\n",
    "        axes[0].axvline(x=config.vip_moderate, color='orange', linestyle='--',\n",
    "                       linewidth=1.5, label=f'Moderate ({config.vip_moderate})')\n",
    "        axes[0].set_xlabel('VIP Score')\n",
    "        axes[0].set_title('PLS Variable Importance')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        if cv_scores:\n",
    "            axes[1].plot(range(1, len(cv_scores) + 1), cv_scores, 'bo-', linewidth=2, markersize=8)\n",
    "            optimal = np.argmax(cv_scores) + 1\n",
    "            axes[1].axvline(x=optimal, color='red', linestyle='--', label=f'Optimal = {optimal}')\n",
    "            axes[1].set_xlabel('Number of Components')\n",
    "            axes[1].set_ylabel('CV R²')\n",
    "            axes[1].set_title('PLS Component Selection')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return self._save_and_show(fig, 'phase1_pls_analysis.png', save_path)\n",
    "    \n",
    "    def multicollinearity_heatmap(self, X: pd.DataFrame, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot feature correlation heatmap.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        feature_corr = X.corr()\n",
    "        mask = np.triu(np.ones_like(feature_corr, dtype=bool), k=0)\n",
    "        sns.heatmap(feature_corr, annot=True, cmap='RdBu_r', center=0, fmt='.2f',\n",
    "                    mask=mask, square=True, linewidths=0.5, ax=ax)\n",
    "        ax.set_title('Feature-Feature Correlations')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return self._save_and_show(fig, 'phase1_multicollinearity.png', save_path)\n",
    "    \n",
    "    def validation_plot(self, loo_actual: np.ndarray, loo_preds: np.ndarray, \n",
    "                        r2: float, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot LOO-CV validation results.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        \n",
    "        axes[0].scatter(loo_actual, loo_preds, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "        lims = [min(loo_actual.min(), loo_preds.min()), max(loo_actual.max(), loo_preds.max())]\n",
    "        axes[0].plot(lims, lims, 'r--', linewidth=2, label='Perfect')\n",
    "        axes[0].set_xlabel('Actual')\n",
    "        axes[0].set_ylabel('Predicted')\n",
    "        axes[0].set_title(f'LOO-CV: R² = {r2:.4f}')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        residuals = loo_actual - loo_preds\n",
    "        axes[1].hist(residuals, bins=12, edgecolor='black', alpha=0.7)\n",
    "        axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "        axes[1].set_xlabel('Residual')\n",
    "        axes[1].set_ylabel('Frequency')\n",
    "        axes[1].set_title(f'Residuals: Mean={residuals.mean():.3f}')\n",
    "        \n",
    "        axes[2].scatter(loo_preds, residuals, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "        axes[2].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "        axes[2].set_xlabel('Predicted')\n",
    "        axes[2].set_ylabel('Residual')\n",
    "        axes[2].set_title('Residuals vs Predicted')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return self._save_and_show(fig, 'phase1_validation.png', save_path)\n",
    "    \n",
    "    def consensus_plot(self, consensus: pd.DataFrame, config: Phase1Config,\n",
    "                       save_path: Optional[str] = None):\n",
    "        \"\"\"Plot consensus ranking visualization.\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # Rankings heatmap\n",
    "        heatmap_data = consensus.set_index('feature')[['rank_corr', 'rank_lasso', 'rank_pls']]\n",
    "        heatmap_data.columns = ['Correlation', 'Lasso', 'PLS']\n",
    "        sns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap='RdYlGn_r', ax=axes[0, 0],\n",
    "                    cbar_kws={'label': 'Rank (lower=better)'})\n",
    "        axes[0, 0].set_title('Rankings Across Methods')\n",
    "        \n",
    "        # Method agreement\n",
    "        colors = ['darkgreen' if a >= 3 else 'orange' if a >= 2 else 'lightcoral' \n",
    "                  for a in consensus['methods_top3']]\n",
    "        axes[0, 1].barh(consensus['feature'][::-1], consensus['methods_top3'][::-1], color=colors[::-1])\n",
    "        axes[0, 1].axvline(x=2, color='orange', linestyle='--', linewidth=2)\n",
    "        axes[0, 1].set_xlabel('Methods Ranking Feature in Top 3')\n",
    "        axes[0, 1].set_title('Method Agreement')\n",
    "        \n",
    "        # Average rank\n",
    "        colors = ['steelblue' if t == 'binary' else 'forestgreen' for t in consensus['type']]\n",
    "        axes[1, 0].barh(consensus['feature'][::-1], consensus['avg_rank'][::-1], color=colors[::-1])\n",
    "        axes[1, 0].set_xlabel('Average Rank (lower = better)')\n",
    "        axes[1, 0].set_title('Consensus Ranking')\n",
    "        axes[1, 0].invert_xaxis()\n",
    "        \n",
    "        # Correlation vs VIP\n",
    "        for _, row in consensus.iterrows():\n",
    "            color = 'steelblue' if row['type'] == 'binary' else 'forestgreen'\n",
    "            marker = 's' if row['has_interaction'] else 'o'\n",
    "            axes[1, 1].scatter(abs(row['correlation']), row['VIP'], c=color, s=100, \n",
    "                              marker=marker, edgecolors='black', linewidth=0.5)\n",
    "            axes[1, 1].annotate(row['feature'], (abs(row['correlation']), row['VIP']), \n",
    "                               fontsize=8, ha='left', va='bottom')\n",
    "        \n",
    "        axes[1, 1].axhline(y=config.vip_important, color='green', linestyle='--', alpha=0.7)\n",
    "        axes[1, 1].axvline(x=config.correlation_strong, color='blue', linestyle='--', alpha=0.7)\n",
    "        axes[1, 1].set_xlabel('|Correlation|')\n",
    "        axes[1, 1].set_ylabel('VIP Score')\n",
    "        axes[1, 1].set_title('Correlation vs VIP')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return self._save_and_show(fig, 'phase1_consensus.png', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Phase1Pipeline Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class Phase1Pipeline:\n",
    "    \"\"\"Complete Phase 1 pipeline for feature screening and selection.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Phase1Config):\n",
    "        self.config = config\n",
    "        self._output_dir = Path(config.output_dir)\n",
    "        self._output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self._loader = DataLoader()\n",
    "        self._ranker = FeatureRanker(config)\n",
    "        self._selector = None\n",
    "        self._checkpoint_mgr = Phase1Checkpoint()\n",
    "        self._plotter = Phase1Plotter(config.output_dir)\n",
    "        \n",
    "        # Data attributes\n",
    "        self._df = None\n",
    "        self._X = None\n",
    "        self._y = None\n",
    "        self._feature_cols = []\n",
    "        self._binary_features = []\n",
    "        self._continuous_features = []\n",
    "        self._binary_mappings = {}\n",
    "        self._validation_metrics = {}\n",
    "        self._bounds_df = None\n",
    "    \n",
    "    def run(self, data_path: Optional[str] = None) -> 'Phase1Pipeline':\n",
    "        \"\"\"Run complete Phase 1 pipeline.\"\"\"\n",
    "        data_path = data_path or self.config.data_file\n",
    "        \n",
    "        print(\"─\" * 60)\n",
    "        print(\"Phase 1: Feature Screening\")\n",
    "        print(\"─\" * 60)\n",
    "        \n",
    "        # Load and prepare data\n",
    "        self._load_data(data_path)\n",
    "        \n",
    "        # Run all ranking methods\n",
    "        self._run_ranking()\n",
    "        \n",
    "        # Auto-select features\n",
    "        self._selector = FeatureSelector(self.config, self._ranker)\n",
    "        self._selector.auto_select(self.config.target_features)\n",
    "        \n",
    "        # Validate selection\n",
    "        self._validate()\n",
    "        \n",
    "        # Generate plots\n",
    "        self._generate_plots()\n",
    "        \n",
    "        self._print_summary()\n",
    "        return self\n",
    "    \n",
    "    def _load_data(self, data_path: str):\n",
    "        \"\"\"Load and prepare data.\"\"\"\n",
    "        print(\"  Loading data...\")\n",
    "        df = self._loader.load_excel(data_path, self.config.sheet_name, self.config.header_row)\n",
    "        \n",
    "        if self.config.split_keyword:\n",
    "            df_initial, _ = self._loader.split_at_keyword(df, self.config.split_keyword)\n",
    "        else:\n",
    "            df_initial = df.copy()\n",
    "        \n",
    "        self._df = self._loader.clean_data(df_initial)\n",
    "        self._feature_cols = self._loader.get_feature_columns(\n",
    "            self._df, self.config.stop_feature, self.config.response_column\n",
    "        )\n",
    "        \n",
    "        self._binary_features, self._continuous_features, self._binary_mappings = \\\n",
    "            self._loader.classify_features(self._df, self._feature_cols)\n",
    "        \n",
    "        feature_cols = self._binary_features + self._continuous_features\n",
    "        self._X = self._df[feature_cols].copy()\n",
    "        self._y = self._df[self.config.response_column].copy()\n",
    "        \n",
    "        # Drop missing response\n",
    "        valid = ~self._y.isnull()\n",
    "        self._X = self._X[valid].reset_index(drop=True)\n",
    "        self._y = self._y[valid].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"  ✓ {len(self._X)} samples, {len(feature_cols)} features\")\n",
    "        print(f\"    Binary: {len(self._binary_features)}, Continuous: {len(self._continuous_features)}\")\n",
    "    \n",
    "    def _run_ranking(self):\n",
    "        \"\"\"Run all feature ranking methods.\"\"\"\n",
    "        print(\"  Running feature ranking...\")\n",
    "        \n",
    "        self._ranker.run_correlation(self._X, self._y, self._binary_features)\n",
    "        self._ranker.run_lasso(self._X, self._y, self._binary_features)\n",
    "        self._ranker.run_pls_vip(self._X, self._y, self._binary_features)\n",
    "        self._ranker.run_interaction_screening(self._X, self._y)\n",
    "        self._ranker.check_multicollinearity(self._X)\n",
    "        \n",
    "        print(\"  ✓ Completed: Correlation, Lasso, PLS-VIP, Interactions, Multicollinearity\")\n",
    "    \n",
    "    def _validate(self):\n",
    "        \"\"\"Validate feature selection.\"\"\"\n",
    "        features = self._selector.selected_features\n",
    "        self._validation_metrics = self._selector.validate_selection(\n",
    "            self._X, self._y, features, self._binary_features, self._continuous_features\n",
    "        )\n",
    "        print(f\"  ✓ Validation R²: {self._validation_metrics['r2']:.4f}\")\n",
    "    \n",
    "    def _generate_plots(self):\n",
    "        \"\"\"Generate all Phase 1 plots.\"\"\"\n",
    "        print(\"  Generating plots...\")\n",
    "        self._plotter.scatter_plots(self._X, self._y, self._binary_features, \n",
    "                                    self.config.response_column)\n",
    "        self._plotter.correlation_plot(self._ranker._corr_df, self.config)\n",
    "        self._plotter.lasso_plot(self._ranker._lasso_df)\n",
    "        self._plotter.pls_plot(self._ranker._pls_df, self.config)\n",
    "        self._plotter.multicollinearity_heatmap(self._X)\n",
    "        self._plotter.consensus_plot(self._selector.consensus, self.config)\n",
    "    \n",
    "    def _print_summary(self):\n",
    "        \"\"\"Print Phase 1 summary.\"\"\"\n",
    "        print(\"\\n\" + \"─\" * 60)\n",
    "        print(\"Selected Features:\")\n",
    "        print(\"─\" * 60)\n",
    "        \n",
    "        consensus = self._selector.consensus\n",
    "        for feat in self._selector.selected_features:\n",
    "            row = consensus[consensus['feature'] == feat].iloc[0]\n",
    "            ftype = \"binary\" if feat in self._binary_features else \"continuous\"\n",
    "            print(f\"  ✓ {feat} ({ftype})\")\n",
    "            print(f\"      Correlation: {row['correlation']:+.3f}, VIP: {row['VIP']:.2f}\")\n",
    "    \n",
    "    def select_features(self, n: Optional[int] = None, \n",
    "                        manual_list: Optional[List[str]] = None) -> List[str]:\n",
    "        \"\"\"Select features (auto or manual override).\"\"\"\n",
    "        if manual_list:\n",
    "            all_features = self._binary_features + self._continuous_features\n",
    "            features, warnings = self._selector.manual_override(manual_list, all_features)\n",
    "            for w in warnings:\n",
    "                print(f\"  {w}\")\n",
    "        else:\n",
    "            features = self._selector.auto_select(n or self.config.target_features)\n",
    "        \n",
    "        # Re-validate\n",
    "        self._validation_metrics = self._selector.validate_selection(\n",
    "            self._X, self._y, features, self._binary_features, self._continuous_features\n",
    "        )\n",
    "        \n",
    "        # Check issues\n",
    "        issues = self._selector.check_selection_issues(self._X, features)\n",
    "        if issues['multicollinearity']:\n",
    "            print(\"  ⚠ Multicollinearity detected:\")\n",
    "            for issue in issues['multicollinearity']:\n",
    "                print(f\"      {issue}\")\n",
    "        if issues['broken_interactions']:\n",
    "            print(\"  ⚠ Broken interactions:\")\n",
    "            for issue in issues['broken_interactions']:\n",
    "                print(f\"      {issue}\")\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def save_checkpoint(self, output_dir: Optional[str] = None) -> None:\n",
    "        \"\"\"Save Phase 1 checkpoint.\"\"\"\n",
    "        output_dir = output_dir or self.config.output_dir\n",
    "        \n",
    "        # Export bounds\n",
    "        self._bounds_df = self._checkpoint_mgr.export_bounds(\n",
    "            self._selector.selected_features, self._X, self._binary_features\n",
    "        )\n",
    "        self._bounds_df.to_csv(Path(output_dir) / 'phase1_bounds.csv', index=False)\n",
    "        \n",
    "        # Build checkpoint dict\n",
    "        checkpoint = {\n",
    "            'metadata': {\n",
    "                'checkpoint_time': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "                'phase1_data_file': self.config.data_file,\n",
    "                'phase1_sheet_name': self.config.sheet_name,\n",
    "                'response_column': self.config.response_column,\n",
    "                'maximize_response': self.config.maximize_response,\n",
    "                'n_initial_experiments': len(self._X),\n",
    "                'n_total_features': len(self._feature_cols),\n",
    "                'n_selected_features': len(self._selector.selected_features),\n",
    "                'target_features': self.config.target_features,\n",
    "            },\n",
    "            'thresholds': {\n",
    "                'correlation_strong': self.config.correlation_strong,\n",
    "                'correlation_moderate': self.config.correlation_moderate,\n",
    "                'vip_important': self.config.vip_important,\n",
    "                'vip_moderate': self.config.vip_moderate,\n",
    "                'multicollinearity_threshold': self.config.multicollinearity_threshold,\n",
    "                'interaction_threshold': self.config.interaction_threshold,\n",
    "            },\n",
    "            'selected_features': self._selector.selected_features,\n",
    "            'all_features': self._binary_features + self._continuous_features,\n",
    "            'binary_features': self._binary_features,\n",
    "            'continuous_features': self._continuous_features,\n",
    "            'selected_binary': [f for f in self._selector.selected_features if f in self._binary_features],\n",
    "            'selected_continuous': [f for f in self._selector.selected_features if f in self._continuous_features],\n",
    "            'binary_mappings': self._binary_mappings,\n",
    "            'validation_metrics': self._validation_metrics,\n",
    "            'response_stats': {\n",
    "                'min': float(self._y.min()), 'max': float(self._y.max()),\n",
    "                'mean': float(self._y.mean()), 'median': float(self._y.median()),\n",
    "                'std': float(self._y.std())\n",
    "            },\n",
    "            'interactions': {\n",
    "                'features_with_interactions': self._ranker.features_with_interactions,\n",
    "                'strong_interactions': self._ranker._interaction_df[\n",
    "                    self._ranker._interaction_df['significant']\n",
    "                ].to_dict('records') if len(self._ranker._interaction_df) > 0 else [],\n",
    "            },\n",
    "            'multicollinearity': {\n",
    "                'high_correlation_pairs': self._ranker.multicollinearity_pairs,\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        self._checkpoint_mgr.save(output_dir, checkpoint)\n",
    "        \n",
    "        # Save additional files\n",
    "        self._selector.consensus.to_csv(Path(output_dir) / 'phase1_consensus_ranking.csv', index=False)\n",
    "        self._df.to_csv(Path(output_dir) / 'phase1_original_data.csv', index=False)\n",
    "    \n",
    "    @property\n",
    "    def data(self) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        return self._X, self._y\n",
    "    \n",
    "    @property\n",
    "    def rankings(self) -> pd.DataFrame:\n",
    "        return self._selector.consensus if self._selector else None\n",
    "    \n",
    "    @property\n",
    "    def selected_features(self) -> List[str]:\n",
    "        return self._selector.selected_features if self._selector else []\n",
    "    \n",
    "    @property\n",
    "    def validation_metrics(self) -> Dict[str, float]:\n",
    "        return self._validation_metrics\n",
    "    \n",
    "    @property\n",
    "    def bounds(self) -> pd.DataFrame:\n",
    "        return self._bounds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ae7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Phase2Scaler Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class Phase2Scaler:\n",
    "    \"\"\"\n",
    "    Scaler for Phase 2 that handles continuous standardization and binary encoding.\n",
    "    Ensures no data leakage by fitting only on training data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, continuous_features: List[str], binary_features: List[str], \n",
    "                 all_features: List[str]):\n",
    "        self.continuous_features = continuous_features\n",
    "        self.binary_features = binary_features\n",
    "        self.all_features = all_features\n",
    "        self._scaler = StandardScaler()\n",
    "        self._is_fitted = False\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame) -> 'Phase2Scaler':\n",
    "        \"\"\"Fit scaler on training data.\"\"\"\n",
    "        if self.continuous_features:\n",
    "            self._scaler.fit(X[self.continuous_features])\n",
    "        self._is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Transform data using fitted scaler.\"\"\"\n",
    "        if not self._is_fitted:\n",
    "            raise ValueError(\"Scaler not fitted. Call fit() first.\")\n",
    "        \n",
    "        X_out = X.copy()\n",
    "        \n",
    "        if self.continuous_features:\n",
    "            X_out[self.continuous_features] = self._scaler.transform(X[self.continuous_features])\n",
    "        \n",
    "        for col in self.binary_features:\n",
    "            if col in X_out.columns:\n",
    "                X_out[col] = X_out[col] * 2 - 1\n",
    "        \n",
    "        return X_out\n",
    "    \n",
    "    def fit_transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Fit and transform in one step.\"\"\"\n",
    "        return self.fit(X).transform(X)\n",
    "    \n",
    "    def inverse_transform_point(self, x_scaled: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Convert a single scaled point back to original space.\"\"\"\n",
    "        x_orig = np.array(x_scaled).copy()\n",
    "        \n",
    "        for i, feat in enumerate(self.all_features):\n",
    "            if feat in self.binary_features:\n",
    "                x_orig[i] = (x_orig[i] + 1) / 2\n",
    "            elif feat in self.continuous_features:\n",
    "                cont_idx = self.continuous_features.index(feat)\n",
    "                x_orig[i] = x_orig[i] * self._scaler.scale_[cont_idx] + self._scaler.mean_[cont_idx]\n",
    "        \n",
    "        return x_orig\n",
    "    \n",
    "    def transform_point(self, x_original: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Convert a single original point to scaled space.\"\"\"\n",
    "        x_scaled = np.array(x_original).copy()\n",
    "        \n",
    "        for i, feat in enumerate(self.all_features):\n",
    "            if feat in self.binary_features:\n",
    "                x_scaled[i] = x_scaled[i] * 2 - 1\n",
    "            elif feat in self.continuous_features:\n",
    "                cont_idx = self.continuous_features.index(feat)\n",
    "                x_scaled[i] = (x_scaled[i] - self._scaler.mean_[cont_idx]) / self._scaler.scale_[cont_idx]\n",
    "        \n",
    "        return x_scaled\n",
    "    \n",
    "    def get_scaled_bounds(self, bounds_array: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Convert bounds to scaled space.\"\"\"\n",
    "        scaled_bounds = []\n",
    "        \n",
    "        for i, feat in enumerate(self.all_features):\n",
    "            if feat in self.binary_features:\n",
    "                scaled_bounds.append([-1, 1])\n",
    "            else:\n",
    "                cont_idx = self.continuous_features.index(feat)\n",
    "                lb = (bounds_array[i, 0] - self._scaler.mean_[cont_idx]) / self._scaler.scale_[cont_idx]\n",
    "                ub = (bounds_array[i, 1] - self._scaler.mean_[cont_idx]) / self._scaler.scale_[cont_idx]\n",
    "                scaled_bounds.append([lb, ub])\n",
    "        \n",
    "        return np.array(scaled_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1c61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# GPModel Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class GPModel:\n",
    "    \"\"\"Gaussian Process model wrapper with validation.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_features: int, n_restarts: int = 10):\n",
    "        self._kernel = (\n",
    "            ConstantKernel(1.0, constant_value_bounds=(1e-3, 1e3)) * \n",
    "            Matern(length_scale=np.ones(n_features), \n",
    "                   length_scale_bounds=(1e-2, 1e2), nu=2.5) + \n",
    "            WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-5, 1e1))\n",
    "        )\n",
    "        self._gp = GaussianProcessRegressor(\n",
    "            kernel=self._kernel,\n",
    "            n_restarts_optimizer=n_restarts,\n",
    "            normalize_y=True,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        self._is_fitted = False\n",
    "    \n",
    "    def fit(self, X: Union[pd.DataFrame, np.ndarray], y: Union[pd.Series, np.ndarray]) -> 'GPModel':\n",
    "        \"\"\"Fit GP model.\"\"\"\n",
    "        X_arr = X.values if hasattr(X, 'values') else X\n",
    "        y_arr = y.values if hasattr(y, 'values') else y\n",
    "        self._gp.fit(X_arr, y_arr)\n",
    "        self._is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: Union[pd.DataFrame, np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Predict with uncertainty.\"\"\"\n",
    "        if not self._is_fitted:\n",
    "            raise ValueError(\"Model not fitted\")\n",
    "        X_arr = X.values if hasattr(X, 'values') else X\n",
    "        X_arr = np.atleast_2d(X_arr)\n",
    "        return self._gp.predict(X_arr, return_std=True)\n",
    "    \n",
    "    def validate_loo(self, X: pd.DataFrame, y: pd.Series, \n",
    "                     scaler_class: type, continuous_features: List[str],\n",
    "                     binary_features: List[str], all_features: List[str]\n",
    "                    ) -> Dict[str, float]:\n",
    "        \"\"\"Perform leakage-free LOO-CV validation.\"\"\"\n",
    "        loo_preds, loo_actual, loo_stds = [], [], []\n",
    "        \n",
    "        for train_idx, test_idx in LeaveOneOut().split(X):\n",
    "            # Scale on training fold only\n",
    "            scaler_temp = scaler_class(continuous_features, binary_features, all_features)\n",
    "            X_train_scaled = scaler_temp.fit_transform(X.iloc[train_idx])\n",
    "            X_test_scaled = scaler_temp.transform(X.iloc[test_idx])\n",
    "            \n",
    "            # Fit GP on training fold\n",
    "            gp_temp = GaussianProcessRegressor(\n",
    "                kernel=self._kernel.clone_with_theta(self._kernel.theta),\n",
    "                n_restarts_optimizer=5,\n",
    "                normalize_y=True,\n",
    "                random_state=RANDOM_STATE\n",
    "            )\n",
    "            gp_temp.fit(X_train_scaled.values, y.iloc[train_idx].values)\n",
    "            \n",
    "            pred, std = gp_temp.predict(X_test_scaled.values, return_std=True)\n",
    "            loo_preds.append(pred[0])\n",
    "            loo_stds.append(std[0])\n",
    "            loo_actual.append(y.iloc[test_idx].values[0])\n",
    "        \n",
    "        loo_preds = np.array(loo_preds)\n",
    "        loo_stds = np.array(loo_stds)\n",
    "        loo_actual = np.array(loo_actual)\n",
    "        \n",
    "        # 95% CI coverage\n",
    "        z_score = 1.96\n",
    "        in_ci = np.sum(np.abs(loo_actual - loo_preds) <= z_score * loo_stds)\n",
    "        coverage = in_ci / len(loo_actual)\n",
    "        \n",
    "        return {\n",
    "            'r2': r2_score(loo_actual, loo_preds),\n",
    "            'rmse': np.sqrt(mean_squared_error(loo_actual, loo_preds)),\n",
    "            'coverage': coverage,\n",
    "            'predictions': loo_preds,\n",
    "            'actual': loo_actual,\n",
    "            'stds': loo_stds\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def log_marginal_likelihood(self) -> float:\n",
    "        return self._gp.log_marginal_likelihood_value_ if self._is_fitted else None\n",
    "    \n",
    "    @property\n",
    "    def kernel_params(self) -> str:\n",
    "        return str(self._gp.kernel_) if self._is_fitted else None\n",
    "    \n",
    "    @property\n",
    "    def gp(self):\n",
    "        return self._gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1188324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# AcquisitionOptimizer Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class AcquisitionOptimizer:\n",
    "    \"\"\"Optimizes acquisition functions for batch selection.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def expected_improvement(X_new: np.ndarray, gp, y_best: float, \n",
    "                             xi: float = 0.01, minimize: bool = True) -> np.ndarray:\n",
    "        \"\"\"Expected Improvement acquisition function.\"\"\"\n",
    "        X_new = np.atleast_2d(X_new)\n",
    "        mu, sigma = gp.predict(X_new, return_std=True)\n",
    "        sigma = np.maximum(sigma, 1e-8)\n",
    "        \n",
    "        improvement = (y_best - mu - xi) if minimize else (mu - y_best - xi)\n",
    "        Z = improvement / sigma\n",
    "        ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei[sigma < 1e-8] = 0.0\n",
    "        return ei\n",
    "    \n",
    "    @staticmethod\n",
    "    def lower_confidence_bound(X_new: np.ndarray, gp, kappa: float = 2.0) -> np.ndarray:\n",
    "        \"\"\"Lower Confidence Bound for minimization.\"\"\"\n",
    "        X_new = np.atleast_2d(X_new)\n",
    "        mu, sigma = gp.predict(X_new, return_std=True)\n",
    "        return mu - kappa * sigma\n",
    "    \n",
    "    @staticmethod\n",
    "    def upper_confidence_bound(X_new: np.ndarray, gp, kappa: float = 2.0) -> np.ndarray:\n",
    "        \"\"\"Upper Confidence Bound for maximization.\"\"\"\n",
    "        X_new = np.atleast_2d(X_new)\n",
    "        mu, sigma = gp.predict(X_new, return_std=True)\n",
    "        return mu + kappa * sigma\n",
    "    \n",
    "    def optimize_batch(self, gp, bounds_scaled: np.ndarray, y_best: float, \n",
    "                       batch_size: int, minimize: bool = True,\n",
    "                       kappa: float = 2.0, n_restarts: int = 20,\n",
    "                       min_distance: float = 0.3) -> pd.DataFrame:\n",
    "        \"\"\"Find batch of diverse points optimizing acquisition function.\"\"\"\n",
    "        \n",
    "        def negative_lcb(x):\n",
    "            x = x.reshape(1, -1)\n",
    "            if minimize:\n",
    "                return self.lower_confidence_bound(x, gp.gp, kappa)[0]\n",
    "            return -self.upper_confidence_bound(x, gp.gp, kappa)[0]\n",
    "        \n",
    "        def negative_ei(x):\n",
    "            x = x.reshape(1, -1)\n",
    "            return -self.expected_improvement(x, gp.gp, y_best, minimize=minimize)[0]\n",
    "        \n",
    "        n_features = bounds_scaled.shape[0]\n",
    "        selected_points = []\n",
    "        \n",
    "        for batch_idx in range(batch_size):\n",
    "            best_candidates = []\n",
    "            \n",
    "            for _ in range(n_restarts):\n",
    "                x0 = np.random.uniform(bounds_scaled[:, 0], bounds_scaled[:, 1])\n",
    "                \n",
    "                try:\n",
    "                    obj_func = negative_ei if batch_idx == 0 else negative_lcb\n",
    "                    result = minimize(obj_func, x0, method='L-BFGS-B', bounds=bounds_scaled)\n",
    "                    \n",
    "                    if result.success:\n",
    "                        if selected_points:\n",
    "                            distances = [np.linalg.norm(result.x - p) for p in selected_points]\n",
    "                            if min(distances) >= min_distance:\n",
    "                                best_candidates.append((result.fun, result.x))\n",
    "                        else:\n",
    "                            best_candidates.append((result.fun, result.x))\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if best_candidates:\n",
    "                best_candidates.sort(key=lambda x: x[0])\n",
    "                selected_points.append(best_candidates[0][1])\n",
    "            else:\n",
    "                # Fallback: random point with distance constraint\n",
    "                for _ in range(100):\n",
    "                    x_rand = np.random.uniform(bounds_scaled[:, 0], bounds_scaled[:, 1])\n",
    "                    if not selected_points or min(np.linalg.norm(x_rand - p) for p in selected_points) >= min_distance:\n",
    "                        selected_points.append(x_rand)\n",
    "                        break\n",
    "        \n",
    "        return np.array(selected_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ddaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# BOIterationManager Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class BOIterationManager:\n",
    "    \"\"\"Manages individual Bayesian Optimization iterations.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Phase2Config, checkpoint: Dict[str, Any]):\n",
    "        self.config = config\n",
    "        self.checkpoint = checkpoint\n",
    "        self._selected_features = checkpoint['selected_features']\n",
    "        self._binary_features = checkpoint['selected_binary']\n",
    "        self._continuous_features = checkpoint['selected_continuous']\n",
    "        self._binary_mappings = checkpoint['binary_mappings']\n",
    "        self._maximize = checkpoint['metadata']['maximize_response']\n",
    "        self._response_column = checkpoint['metadata']['response_column']\n",
    "        \n",
    "        self._optimizer = AcquisitionOptimizer()\n",
    "        self._current_gp = None\n",
    "        self._current_scaler = None\n",
    "        self._validation_metrics = None\n",
    "    \n",
    "    def run_iteration(self, X: pd.DataFrame, y: pd.Series, \n",
    "                      bounds_array: np.ndarray, iteration: int) -> pd.DataFrame:\n",
    "        \"\"\"Run single BO iteration and return proposed experiments.\"\"\"\n",
    "        \n",
    "        # Fit scaler\n",
    "        self._current_scaler = Phase2Scaler(\n",
    "            self._continuous_features, self._binary_features, self._selected_features\n",
    "        )\n",
    "        X_scaled = self._current_scaler.fit_transform(X)\n",
    "        scaled_bounds = self._current_scaler.get_scaled_bounds(bounds_array)\n",
    "        \n",
    "        # Fit GP\n",
    "        self._current_gp = GPModel(len(self._selected_features))\n",
    "        self._current_gp.fit(X_scaled, y)\n",
    "        \n",
    "        # Validate\n",
    "        self._validation_metrics = self._current_gp.validate_loo(\n",
    "            X, y, Phase2Scaler, self._continuous_features, \n",
    "            self._binary_features, self._selected_features\n",
    "        )\n",
    "        \n",
    "        # Get current best\n",
    "        y_best = y.max() if self._maximize else y.min()\n",
    "        \n",
    "        # Optimize acquisition\n",
    "        next_points_scaled = self._optimizer.optimize_batch(\n",
    "            self._current_gp, scaled_bounds, y_best, self.config.batch_size,\n",
    "            minimize=not self._maximize, kappa=self.config.exploration_weight,\n",
    "            n_restarts=self.config.n_optimizer_restarts,\n",
    "            min_distance=self.config.min_distance_between_points\n",
    "        )\n",
    "        \n",
    "        # Convert to original scale and build DataFrame\n",
    "        return self._build_experiments_df(next_points_scaled, iteration)\n",
    "    \n",
    "    def _build_experiments_df(self, points_scaled: np.ndarray, iteration: int) -> pd.DataFrame:\n",
    "        \"\"\"Build DataFrame of proposed experiments.\"\"\"\n",
    "        experiments = []\n",
    "        \n",
    "        for i, x_scaled in enumerate(points_scaled):\n",
    "            x_orig = self._current_scaler.inverse_transform_point(x_scaled)\n",
    "            \n",
    "            row = {'Experiment_ID': f'Iter{iteration}_Exp{i+1}'}\n",
    "            \n",
    "            for j, feat in enumerate(self._selected_features):\n",
    "                if feat in self._binary_features:\n",
    "                    row[feat] = int(round(np.clip(x_orig[j], 0, 1)))\n",
    "                else:\n",
    "                    row[feat] = round(x_orig[j], 4)\n",
    "            \n",
    "            mu, sigma = self._current_gp.predict(x_scaled.reshape(1, -1))\n",
    "            row['GP_Predicted_Mean'] = round(mu[0], 4)\n",
    "            row['GP_Predicted_Std'] = round(sigma[0], 4)\n",
    "            row['Acquisition_Rank'] = i + 1\n",
    "            \n",
    "            experiments.append(row)\n",
    "        \n",
    "        return pd.DataFrame(experiments)\n",
    "    \n",
    "    def input_results(self, results_df: pd.DataFrame, X: pd.DataFrame, \n",
    "                      y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"Add new experimental results to dataset.\"\"\"\n",
    "        X_new = results_df[self._selected_features].copy()\n",
    "        y_new = results_df[self._response_column].copy()\n",
    "        \n",
    "        X_updated = pd.concat([X, X_new], ignore_index=True)\n",
    "        y_updated = pd.concat([y, y_new], ignore_index=True)\n",
    "        \n",
    "        return X_updated, y_updated\n",
    "    \n",
    "    def check_convergence(self, history: Dict, threshold: float, \n",
    "                         patience: int) -> Tuple[bool, str]:\n",
    "        \"\"\"Check if optimization has converged.\"\"\"\n",
    "        best_values = history['best_values']\n",
    "        \n",
    "        if len(best_values) < 2:\n",
    "            return False, \"Not enough iterations\"\n",
    "        \n",
    "        # Calculate improvements\n",
    "        improvements = []\n",
    "        for i in range(1, len(best_values)):\n",
    "            imp = (best_values[i] - best_values[i-1]) if self._maximize else (best_values[i-1] - best_values[i])\n",
    "            improvements.append(imp)\n",
    "        \n",
    "        recent = improvements[-patience:] if len(improvements) >= patience else improvements\n",
    "        max_recent = max(recent) if recent else 0\n",
    "        \n",
    "        converged = max_recent < threshold\n",
    "        \n",
    "        report = f\"Max improvement (last {patience}): {max_recent:.6f}, Threshold: {threshold}\"\n",
    "        return converged, report\n",
    "    \n",
    "    @property\n",
    "    def gp(self) -> GPModel:\n",
    "        return self._current_gp\n",
    "    \n",
    "    @property\n",
    "    def scaler(self) -> Phase2Scaler:\n",
    "        return self._current_scaler\n",
    "    \n",
    "    @property\n",
    "    def validation(self) -> Dict[str, float]:\n",
    "        return self._validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Phase2Plotter Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class Phase2Plotter:\n",
    "    \"\"\"Plotting utilities for Phase 2 Bayesian Optimization.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    def _save_and_show(self, fig, filename: str, save_path: Optional[str] = None):\n",
    "        path = save_path or (self.output_dir / filename)\n",
    "        plt.savefig(path, dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        return fig\n",
    "    \n",
    "    def gp_slices(self, gp, scaler, X: pd.DataFrame, y: pd.Series,\n",
    "                  bounds_df: pd.DataFrame, selected_features: List[str],\n",
    "                  binary_features: List[str], experiments_df: pd.DataFrame,\n",
    "                  iteration: int, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot 1D GP slices for each feature.\"\"\"\n",
    "        n_features = len(selected_features)\n",
    "        fig, axes = plt.subplots(1, n_features, figsize=(4*n_features, 4))\n",
    "        if n_features == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        X_scaled = scaler.transform(X)\n",
    "        x_base = X_scaled.mean().values.copy()\n",
    "        \n",
    "        for i, feat in enumerate(selected_features):\n",
    "            ax = axes[i]\n",
    "            bounds_row = bounds_df[bounds_df['feature'] == feat].iloc[0]\n",
    "            \n",
    "            if feat in binary_features:\n",
    "                preds, stds = [], []\n",
    "                for val in [-1, 1]:\n",
    "                    x_test = x_base.copy()\n",
    "                    x_test[i] = val\n",
    "                    mu, sigma = gp.predict(x_test.reshape(1, -1))\n",
    "                    preds.append(mu[0])\n",
    "                    stds.append(sigma[0])\n",
    "                ax.bar([0, 1], preds, yerr=[1.96*s for s in stds], capsize=5, alpha=0.7)\n",
    "                ax.set_xticks([0, 1])\n",
    "            else:\n",
    "                x_grid = np.linspace(bounds_row['min'], bounds_row['max'], 50)\n",
    "                preds, stds = [], []\n",
    "                \n",
    "                for val in x_grid:\n",
    "                    x_test = x_base.copy()\n",
    "                    x_test[i] = scaler.transform_point(\n",
    "                        [val if j == i else X[selected_features[j]].mean() \n",
    "                         for j in range(len(selected_features))]\n",
    "                    )[i]\n",
    "                    mu, sigma = gp.predict(x_test.reshape(1, -1))\n",
    "                    preds.append(mu[0])\n",
    "                    stds.append(sigma[0])\n",
    "                \n",
    "                preds, stds = np.array(preds), np.array(stds)\n",
    "                ax.plot(x_grid, preds, 'b-', linewidth=2)\n",
    "                ax.fill_between(x_grid, preds - 1.96*stds, preds + 1.96*stds, alpha=0.3)\n",
    "                ax.scatter(X[feat], y, c='red', s=50, zorder=5)\n",
    "                \n",
    "                for _, row in experiments_df.iterrows():\n",
    "                    ax.axvline(row[feat], color='green', linestyle='--', alpha=0.5)\n",
    "            \n",
    "            ax.set_xlabel(feat)\n",
    "            ax.set_title(f'GP: {feat}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return self._save_and_show(fig, f'phase2_iteration{iteration}_gp.png', save_path)\n",
    "    \n",
    "    def validation_plot(self, validation: Dict, iteration: int, \n",
    "                        save_path: Optional[str] = None):\n",
    "        \"\"\"Plot GP validation results.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        actual = validation['actual']\n",
    "        preds = validation['predictions']\n",
    "        stds = validation['stds']\n",
    "        \n",
    "        axes[0].errorbar(actual, preds, yerr=1.96*stds, fmt='o', alpha=0.7, capsize=3)\n",
    "        lims = [min(actual.min(), preds.min()), max(actual.max(), preds.max())]\n",
    "        axes[0].plot(lims, lims, 'r--', linewidth=2)\n",
    "        axes[0].set_xlabel('Actual')\n",
    "        axes[0].set_ylabel('Predicted')\n",
    "        axes[0].set_title(f'LOO-CV: R² = {validation[\"r2\"]:.3f}')\n",
    "        \n",
    "        residuals = actual - preds\n",
    "        axes[1].hist(residuals, bins=15, edgecolor='black', alpha=0.7)\n",
    "        axes[1].axvline(0, color='red', linestyle='--')\n",
    "        axes[1].set_xlabel('Residual')\n",
    "        axes[1].set_title('Residual Distribution')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return self._save_and_show(fig, f'phase2_iteration{iteration}_validation.png', save_path)\n",
    "    \n",
    "    def optimization_progress(self, history: Dict, response_name: str,\n",
    "                              save_path: Optional[str] = None):\n",
    "        \"\"\"Plot optimization progress over iterations.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        axes[0].plot(history['iterations'], history['best_values'], 'bo-', linewidth=2, markersize=10)\n",
    "        axes[0].set_xlabel('Iteration')\n",
    "        axes[0].set_ylabel(f'Best {response_name}')\n",
    "        axes[0].set_title('Optimization Progress')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        r2_values = [p['loo_r2'] for p in history['gp_params']]\n",
    "        axes[1].plot(history['iterations'], r2_values, 'go-', linewidth=2, markersize=10)\n",
    "        axes[1].set_xlabel('Iteration')\n",
    "        axes[1].set_ylabel('LOO-CV R²')\n",
    "        axes[1].set_title('GP Model Quality')\n",
    "        axes[1].set_ylim([0, 1])\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return self._save_and_show(fig, 'phase2_progress.png', save_path)\n",
    "    \n",
    "    def final_summary(self, X: pd.DataFrame, y: pd.Series, \n",
    "                      history: Dict, current_best: float,\n",
    "                      response_name: str, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot final optimization summary.\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # Progress\n",
    "        axes[0, 0].plot(history['iterations'], history['best_values'], 'bo-', linewidth=2, markersize=10)\n",
    "        axes[0, 0].set_xlabel('Iteration')\n",
    "        axes[0, 0].set_ylabel(f'Best {response_name}')\n",
    "        axes[0, 0].set_title('Optimization Progress')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # GP Quality\n",
    "        r2_values = [p['loo_r2'] for p in history['gp_params']]\n",
    "        axes[0, 1].plot(history['iterations'], r2_values, 'go-', linewidth=2, markersize=10)\n",
    "        axes[0, 1].set_xlabel('Iteration')\n",
    "        axes[0, 1].set_ylabel('LOO-CV R²')\n",
    "        axes[0, 1].set_title('GP Model Quality')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Response distribution\n",
    "        axes[1, 0].hist(y, bins=20, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "        axes[1, 0].axvline(current_best, color='red', linewidth=2, linestyle='--', label=f'Best: {current_best:.4f}')\n",
    "        axes[1, 0].set_xlabel(response_name)\n",
    "        axes[1, 0].set_title(f'Distribution of {response_name}')\n",
    "        axes[1, 0].legend()\n",
    "        \n",
    "        # Feature correlations\n",
    "        correlations = X.corrwith(y)\n",
    "        colors = ['forestgreen' if c > 0 else 'crimson' for c in correlations]\n",
    "        axes[1, 1].barh(X.columns, np.abs(correlations), color=colors)\n",
    "        axes[1, 1].set_xlabel('|Correlation|')\n",
    "        axes[1, 1].set_title('Feature-Response Correlations')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return self._save_and_show(fig, 'phase2_final_summary.png', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Phase2Pipeline Class\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class Phase2Pipeline:\n",
    "    \"\"\"Complete Phase 2 pipeline for Bayesian Optimization.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Phase2Config):\n",
    "        self.config = config\n",
    "        self._output_dir = Path(config.output_dir)\n",
    "        self._output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self._checkpoint = None\n",
    "        self._bounds_df = None\n",
    "        self._bounds_array = None\n",
    "        self._X = None\n",
    "        self._y = None\n",
    "        self._iteration = 0\n",
    "        self._is_converged = False\n",
    "        \n",
    "        self._iteration_mgr = None\n",
    "        self._plotter = Phase2Plotter(config.output_dir)\n",
    "        \n",
    "        self._history = {\n",
    "            'iterations': [],\n",
    "            'best_values': [],\n",
    "            'proposed_points': [],\n",
    "            'observed_responses': [],\n",
    "            'gp_params': []\n",
    "        }\n",
    "    \n",
    "    def load_checkpoint(self, path: Optional[str] = None) -> 'Phase2Pipeline':\n",
    "        \"\"\"Load Phase 1 checkpoint.\"\"\"\n",
    "        path = path or self.config.checkpoint_path\n",
    "        \n",
    "        checkpoint_mgr = Phase1Checkpoint()\n",
    "        self._checkpoint = checkpoint_mgr.load(path)\n",
    "        \n",
    "        self._bounds_df = pd.read_csv(Path(path).parent / 'phase1_bounds.csv')\n",
    "        self._bounds_array = np.array([\n",
    "            [row['min'], row['max']] \n",
    "            for _, row in self._bounds_df.iterrows()\n",
    "        ])\n",
    "        \n",
    "        self._iteration_mgr = BOIterationManager(self.config, self._checkpoint)\n",
    "        \n",
    "        print(f\"✓ Loaded checkpoint\")\n",
    "        print(f\"  Features: {self._checkpoint['selected_features']}\")\n",
    "        print(f\"  Response: {self._checkpoint['metadata']['response_column']}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def load_data(self, data_path: Optional[str] = None) -> 'Phase2Pipeline':\n",
    "        \"\"\"Load Phase 2 experimental data.\"\"\"\n",
    "        data_path = data_path or self.config.data_file\n",
    "        selected_features = self._checkpoint['selected_features']\n",
    "        response_col = self._checkpoint['metadata']['response_column']\n",
    "        \n",
    "        if data_path.endswith('.csv'):\n",
    "            df = pd.read_csv(data_path)\n",
    "        else:\n",
    "            df = pd.read_excel(data_path, sheet_name=self.config.sheet_name)\n",
    "        \n",
    "        # Validate columns\n",
    "        missing = [c for c in selected_features + [response_col] if c not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing columns: {missing}\")\n",
    "        \n",
    "        self._X = df[selected_features].copy()\n",
    "        self._y = df[response_col].copy()\n",
    "        \n",
    "        # Handle missing\n",
    "        valid = ~self._y.isnull() & self._X.notna().all(axis=1)\n",
    "        self._X = self._X[valid].reset_index(drop=True)\n",
    "        self._y = self._y[valid].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"✓ Loaded {len(self._X)} experiments\")\n",
    "        print(f\"  Current best: {self.current_best:.4f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def run_iteration(self) -> pd.DataFrame:\n",
    "        \"\"\"Run single BO iteration and return proposed experiments.\"\"\"\n",
    "        self._iteration += 1\n",
    "        \n",
    "        print(f\"\\n─ Iteration {self._iteration}\")\n",
    "        \n",
    "        experiments_df = self._iteration_mgr.run_iteration(\n",
    "            self._X, self._y, self._bounds_array, self._iteration\n",
    "        )\n",
    "        \n",
    "        validation = self._iteration_mgr.validation\n",
    "        print(f\"  GP R²: {validation['r2']:.4f}, Coverage: {validation['coverage']:.1%}\")\n",
    "        print(f\"  ✓ Proposed {len(experiments_df)} experiments\")\n",
    "        \n",
    "        # Update history\n",
    "        self._history['iterations'].append(self._iteration)\n",
    "        self._history['best_values'].append(self.current_best)\n",
    "        self._history['proposed_points'].append(experiments_df.to_dict('records'))\n",
    "        self._history['gp_params'].append({\n",
    "            'log_marginal_likelihood': self._iteration_mgr.gp.log_marginal_likelihood,\n",
    "            'kernel_params': self._iteration_mgr.gp.kernel_params,\n",
    "            'loo_r2': validation['r2'],\n",
    "            'loo_rmse': validation['rmse'],\n",
    "            'ci_coverage': validation['coverage']\n",
    "        })\n",
    "        \n",
    "        # Save history\n",
    "        self._save_history()\n",
    "        \n",
    "        # Export experiments\n",
    "        response_col = self._checkpoint['metadata']['response_column']\n",
    "        export_df = experiments_df.copy()\n",
    "        export_df[response_col] = ''\n",
    "        export_path = self._output_dir / f'phase2_iteration{self._iteration}_experiments.csv'\n",
    "        export_df.to_csv(export_path, index=False)\n",
    "        \n",
    "        # Generate plots\n",
    "        self._plotter.validation_plot(validation, self._iteration)\n",
    "        \n",
    "        return experiments_df\n",
    "    \n",
    "    def add_results(self, results: Union[str, pd.DataFrame]) -> 'Phase2Pipeline':\n",
    "        \"\"\"Add new experimental results.\"\"\"\n",
    "        if isinstance(results, str):\n",
    "            results_df = pd.read_csv(results)\n",
    "        else:\n",
    "            results_df = results\n",
    "        \n",
    "        response_col = self._checkpoint['metadata']['response_column']\n",
    "        \n",
    "        # Convert response to numeric\n",
    "        results_df[response_col] = pd.to_numeric(results_df[response_col], errors='coerce')\n",
    "        valid_results = results_df[~results_df[response_col].isna()]\n",
    "        \n",
    "        if len(valid_results) == 0:\n",
    "            print(\"  ⚠ No valid results found\")\n",
    "            return self\n",
    "        \n",
    "        # Store previous best\n",
    "        prev_best = self.current_best\n",
    "        \n",
    "        # Update data\n",
    "        self._X, self._y = self._iteration_mgr.input_results(valid_results, self._X, self._y)\n",
    "        \n",
    "        self._history['observed_responses'].append(\n",
    "            valid_results[response_col].tolist()\n",
    "        )\n",
    "        \n",
    "        # Calculate improvement\n",
    "        new_best = self.current_best\n",
    "        maximize = self._checkpoint['metadata']['maximize_response']\n",
    "        improvement = (new_best - prev_best) if maximize else (prev_best - new_best)\n",
    "        \n",
    "        print(f\"  ✓ Added {len(valid_results)} results\")\n",
    "        print(f\"  Previous best: {prev_best:.4f} → New best: {new_best:.4f}\")\n",
    "        if improvement > 0:\n",
    "            print(f\"  ✓ Improvement: {improvement:.4f}\")\n",
    "        \n",
    "        # Save updated data\n",
    "        self._save_all_data()\n",
    "        \n",
    "        # Check convergence\n",
    "        converged, report = self._iteration_mgr.check_convergence(\n",
    "            self._history, self.config.improvement_threshold, self.config.patience\n",
    "        )\n",
    "        self._is_converged = converged\n",
    "        if converged:\n",
    "            print(f\"  ✓ Converged: {report}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_optimal(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get optimal conditions found.\"\"\"\n",
    "        maximize = self._checkpoint['metadata']['maximize_response']\n",
    "        best_idx = self._y.idxmax() if maximize else self._y.idxmin()\n",
    "        \n",
    "        result = {\n",
    "            'response': float(self._y[best_idx]),\n",
    "            'conditions': {feat: float(self._X.loc[best_idx, feat]) \n",
    "                          for feat in self._checkpoint['selected_features']}\n",
    "        }\n",
    "        return result\n",
    "    \n",
    "    def generate_confirmation_runs(self, n: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Generate confirmation runs at optimal conditions.\"\"\"\n",
    "        optimal = self.get_optimal()\n",
    "        response_col = self._checkpoint['metadata']['response_column']\n",
    "        \n",
    "        runs = []\n",
    "        for i in range(n):\n",
    "            row = {'Run_ID': f'Confirm_{i+1}'}\n",
    "            row.update(optimal['conditions'])\n",
    "            row[f'Expected_{response_col}'] = optimal['response']\n",
    "            row[f'Actual_{response_col}'] = ''\n",
    "            runs.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(runs)\n",
    "        df.to_csv(self._output_dir / 'phase2_confirmation_runs.csv', index=False)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _save_history(self):\n",
    "        \"\"\"Save optimization history.\"\"\"\n",
    "        with open(self._output_dir / 'phase2_bo_history.pkl', 'wb') as f:\n",
    "            pickle.dump(self._history, f)\n",
    "        with open(self._output_dir / 'phase2_bo_history.json', 'w') as f:\n",
    "            json.dump(self._history, f, indent=2, default=str)\n",
    "    \n",
    "    def _save_all_data(self):\n",
    "        \"\"\"Save all experimental data.\"\"\"\n",
    "        data = self._X.copy()\n",
    "        data[self._checkpoint['metadata']['response_column']] = self._y.values\n",
    "        data.to_csv(self._output_dir / 'phase2_all_data.csv', index=False)\n",
    "    \n",
    "    def plot_progress(self, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot optimization progress.\"\"\"\n",
    "        return self._plotter.optimization_progress(\n",
    "            self._history, self._checkpoint['metadata']['response_column'], save_path\n",
    "        )\n",
    "    \n",
    "    def plot_final_summary(self, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot final optimization summary.\"\"\"\n",
    "        return self._plotter.final_summary(\n",
    "            self._X, self._y, self._history, self.current_best,\n",
    "            self._checkpoint['metadata']['response_column'], save_path\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def current_best(self) -> float:\n",
    "        if self._y is None or len(self._y) == 0:\n",
    "            return None\n",
    "        maximize = self._checkpoint['metadata']['maximize_response']\n",
    "        return float(self._y.max() if maximize else self._y.min())\n",
    "    \n",
    "    @property\n",
    "    def iteration(self) -> int:\n",
    "        return self._iteration\n",
    "    \n",
    "    @property\n",
    "    def is_converged(self) -> bool:\n",
    "        return self._is_converged\n",
    "    \n",
    "    @property\n",
    "    def history(self) -> Dict:\n",
    "        return self._history\n",
    "    \n",
    "    @property\n",
    "    def data(self) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        return self._X, self._y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcee17a",
   "metadata": {},
   "source": [
    "---\n",
    "# Usage Examples\n",
    "---\n",
    "\n",
    "The following cells demonstrate how to use the modular pipeline classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd640e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Phase 1 Example Usage\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Configure Phase 1\n",
    "config = Phase1Config(\n",
    "    data_file='data.xlsx',\n",
    "    response_column='Downy Leak',\n",
    "    sheet_name='data',\n",
    "    header_row=5,\n",
    "    split_keyword='PREDICTED OPTIMUM RUNS',\n",
    "    stop_feature='Batch ID',\n",
    "    maximize_response=False,\n",
    "    target_features=4\n",
    ")\n",
    "\n",
    "# Run Phase 1 pipeline\n",
    "p1 = Phase1Pipeline(config)\n",
    "p1.run()\n",
    "\n",
    "# Inspect results\n",
    "print(\"\\nRankings:\")\n",
    "print(p1.rankings[['feature', 'correlation', 'VIP', 'avg_rank']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b716f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Manual Feature Override (Optional)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Option 1: Use automatic selection (already done in run())\n",
    "print(\"Auto-selected features:\", p1.selected_features)\n",
    "\n",
    "# Option 2: Manual override - uncomment to use\n",
    "# p1.select_features(manual_list=['Feature_A', 'Feature_B', 'Feature_C', 'Feature_D'])\n",
    "\n",
    "# Validation metrics\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"  R²:   {p1.validation_metrics['r2']:.4f}\")\n",
    "print(f\"  RMSE: {p1.validation_metrics['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {p1.validation_metrics['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Save Phase 1 Checkpoint\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "p1.save_checkpoint()\n",
    "\n",
    "print(\"\\nCheckpoint saved. Files created:\")\n",
    "print(\"  ✓ phase1_checkpoint.json\")\n",
    "print(\"  ✓ phase1_checkpoint.pkl\")\n",
    "print(\"  ✓ phase1_bounds.csv\")\n",
    "print(\"  ✓ phase1_consensus_ranking.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543cb1c",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 2: Bayesian Optimization\n",
    "\n",
    "**Run these cells after:**\n",
    "1. You have selected final features (Phase 1)\n",
    "2. You have run new experiments with those features\n",
    "3. You have created a new data file with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d26d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Phase 2 Configuration and Setup\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Configure Phase 2\n",
    "p2_config = Phase2Config(\n",
    "    data_file='phase2_experiments.xlsx',\n",
    "    checkpoint_path='bo_pipeline_output/phase1_checkpoint.pkl',\n",
    "    batch_size=5,\n",
    "    exploration_weight=2.0,\n",
    "    max_iterations=10,\n",
    "    improvement_threshold=0.01,\n",
    "    patience=3\n",
    ")\n",
    "\n",
    "# Initialize Phase 2 pipeline\n",
    "p2 = Phase2Pipeline(p2_config)\n",
    "p2.load_checkpoint()\n",
    "p2.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Run BO Iteration\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Run single iteration\n",
    "experiments = p2.run_iteration()\n",
    "\n",
    "# View proposed experiments\n",
    "print(\"\\nProposed Experiments:\")\n",
    "print(experiments.to_string(index=False))\n",
    "\n",
    "# Save to CSV for lab\n",
    "experiments.to_csv(f'bo_pipeline_output/next_batch.csv', index=False)\n",
    "print(\"\\n✓ Saved to next_batch.csv - Run these experiments in lab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e1a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Add Results and Continue (Run after lab experiments)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Load completed results\n",
    "# p2.add_results('bo_pipeline_output/next_batch_completed.csv')\n",
    "\n",
    "# Or continue in a loop:\n",
    "# while not p2.is_converged:\n",
    "#     experiments = p2.run_iteration()\n",
    "#     experiments.to_csv('next_batch.csv')\n",
    "#     # [Run experiments in lab]\n",
    "#     # [Fill in results in next_batch.csv]\n",
    "#     p2.add_results('next_batch.csv')\n",
    "\n",
    "print(\"Iteration complete. Waiting for experimental results...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Final Results\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Get optimal conditions\n",
    "optimal = p2.get_optimal()\n",
    "print(\"Optimal Conditions Found:\")\n",
    "print(f\"  Response: {optimal['response']:.4f}\")\n",
    "for feat, val in optimal['conditions'].items():\n",
    "    print(f\"  {feat}: {val:.4f}\")\n",
    "\n",
    "# Generate confirmation runs\n",
    "confirmation = p2.generate_confirmation_runs(5)\n",
    "print(\"\\nConfirmation Runs:\")\n",
    "print(confirmation.to_string(index=False))\n",
    "\n",
    "# Plot final summary\n",
    "p2.plot_final_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff770d",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick Reference\n",
    "\n",
    "### Phase 1 Classes\n",
    "| Class | Purpose |\n",
    "|-------|---------|\n",
    "| `Phase1Config` | Configuration dataclass for Phase 1 |\n",
    "| `DataLoader` | Load, clean, and classify data |\n",
    "| `FeatureRanker` | Correlation, Lasso, PLS-VIP, interactions |\n",
    "| `FeatureSelector` | Auto/manual feature selection with validation |\n",
    "| `Phase1Checkpoint` | Save/load checkpoint files |\n",
    "| `Phase1Pipeline` | Full Phase 1 workflow |\n",
    "\n",
    "### Phase 2 Classes\n",
    "| Class | Purpose |\n",
    "|-------|---------|\n",
    "| `Phase2Config` | Configuration dataclass for Phase 2 |\n",
    "| `Phase2Scaler` | Leakage-free scaling |\n",
    "| `GPModel` | Gaussian Process with LOO-CV validation |\n",
    "| `AcquisitionOptimizer` | EI, LCB, UCB optimization |\n",
    "| `BOIterationManager` | Single iteration management |\n",
    "| `Phase2Pipeline` | Full Phase 2 workflow |\n",
    "\n",
    "### Key Properties\n",
    "- `p1.rankings` - Feature consensus ranking DataFrame\n",
    "- `p1.selected_features` - List of selected feature names\n",
    "- `p1.validation_metrics` - Dict with r2, rmse, mae\n",
    "- `p2.current_best` - Current best response value\n",
    "- `p2.is_converged` - Boolean convergence status\n",
    "- `p2.history` - Optimization history dict"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
